{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 · bHLH anchors (PF00010) — ASC project\n",
    "\n",
    "**Goal:** scan full-length ASC proteins (`ASC_targets.fasta`) with `PF00010.hmm` (bHLH) to detect **all bHLH domains per protein**, derive anchor positions (domain centers), and export clean TSV/GFF/JSON for downstream motif analysis (MEME) and tree overlays.\n",
    "\n",
    "**Notes**\n",
    "- We analyze **whole protein sequences**, not only C‑terminal regions.\n",
    "- Multiple bHLH domains per protein are supported.\n",
    "- Works with `hmmsearch` (preferred) or falls back to `hmmscan` if needed.\n",
    "- Input files are expected in `data/` as set by the `0_setup` notebook/script.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: /Users/gorkemdurmaz/Desktop/asc_project_10\n",
      "Data dir: /Users/gorkemdurmaz/Desktop/asc_project_10/data\n",
      "Targets: /Users/gorkemdurmaz/Desktop/asc_project_10/data/ASC_targets.fasta exists: True\n",
      "PF00010.hmm: /Users/gorkemdurmaz/Desktop/asc_project_10/data/PF00010.hmm exists: True\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, subprocess, sys, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "#  Project paths \n",
    "PROJ = Path.cwd().resolve().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA = PROJ / \"data\"\n",
    "OUT  = PROJ / \"results\"\n",
    "CLADES = OUT / \"clades\"\n",
    "MOTIFS = OUT / \"motifs\"\n",
    "REPORTS = OUT / \"reports\"\n",
    "\n",
    "for d in (DATA, OUT, CLADES, MOTIFS, REPORTS):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# inputs\n",
    "IN_TARGETS = DATA / \"ASC_targets.fasta\"     # proteins, ungapped\n",
    "HMM_PF00010 = DATA / \"PF00010.hmm\"          # pressed already (h3*)\n",
    "PFAM_A = DATA / \"Pfam-A.hmm\"                # optional; not required here\n",
    "\n",
    "print(\"Project:\", PROJ)\n",
    "print(\"Data dir:\", DATA)\n",
    "print(\"Targets:\", IN_TARGETS, \"exists:\", IN_TARGETS.exists())\n",
    "print(\"PF00010.hmm:\", HMM_PF00010, \"exists:\", HMM_PF00010.exists())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "- `EVALUE_SEQ_MAX`: maximum full-sequence E-value to keep a hit.\n",
    "- `EVALUE_DOM_MAX`: maximum domain (independent) E-value to keep a domain.\n",
    "- `MIN_DOM_SCORE`: optional lower bound on domain bit score.\n",
    "- `CPU`: threads to give HMMER.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/gorkemdurmaz/Desktop/asc_project_10/results/hmm/PF00010_vs_ASC_targets.20251017_132511.domtblout\n"
     ]
    }
   ],
   "source": [
    "EVALUE_SEQ_MAX = 5e-4 #filters sequences based on their overall match probability to the HMM\n",
    "EVALUE_DOM_MAX = 5e-4 #per-domain cutoff ensures that the detected bHLH region itself is statistically significant, even if the rest of the sequence aligns poorly\n",
    "MIN_DOM_SCORE  = 50  # typical “trusted cutoffs” for Pfam domains range between 30–40 bits for marginal significance and >50 bits for strong matches\n",
    "CPU = max(1, (os.cpu_count() or 2) // 2)\n",
    "RUN_DIR = OUT / \"hmm\"; RUN_DIR.mkdir(exist_ok=True, parents=True)\n",
    "STAMP = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "DOMTBL = RUN_DIR / f\"PF00010_vs_ASC_targets.{STAMP}.domtblout\"\n",
    "LOG    = RUN_DIR / f\"PF00010_vs_ASC_targets.{STAMP}.log\"\n",
    "print(DOMTBL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find HMMER binary (hmmsearch preferred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmmsearch: /Users/gorkemdurmaz/miniconda3/envs/asc/bin/hmmsearch\n",
      "hmmscan: /Users/gorkemdurmaz/miniconda3/envs/asc/bin/hmmscan\n"
     ]
    }
   ],
   "source": [
    "from shutil import which\n",
    "\n",
    "HMMSEARCH = which(\"hmmsearch\")\n",
    "HMMSCAN   = which(\"hmmscan\")\n",
    "print(\"hmmsearch:\", HMMSEARCH)\n",
    "print(\"hmmscan:\", HMMSCAN)\n",
    "\n",
    "if HMMSEARCH is None and HMMSCAN is None:\n",
    "    raise SystemExit(\"Neither hmmsearch nor hmmscan found on PATH. Please install HMMER3.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run scan\n",
    "- If `hmmsearch` is available, search the PF00010 model against sequences.\n",
    "- Else fall back to `hmmscan` (sequence DB is HMMs; here it is just a single PF00010 model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: /Users/gorkemdurmaz/miniconda3/envs/asc/bin/hmmsearch --domtblout /Users/gorkemdurmaz/Desktop/asc_project_10/results/hmm/PF00010_vs_ASC_targets.20251017_132511.domtblout --cpu 7 /Users/gorkemdurmaz/Desktop/asc_project_10/data/PF00010.hmm /Users/gorkemdurmaz/Desktop/asc_project_10/data/ASC_targets.fasta\n",
      "Return code: 0\n"
     ]
    }
   ],
   "source": [
    "cmd = None\n",
    "if HMMSEARCH:\n",
    "    cmd = [HMMSEARCH, \"--domtblout\", str(DOMTBL), \"--cpu\", str(CPU), str(HMM_PF00010), str(IN_TARGETS)]\n",
    "    mode = \"hmmsearch\"\n",
    "elif HMMSCAN:\n",
    "    cmd = [HMMSCAN, \"--domtblout\", str(DOMTBL), \"--cpu\", str(CPU), str(HMM_PF00010), str(IN_TARGETS)]\n",
    "    mode = \"hmmscan\"\n",
    "\n",
    "print(\"Running:\", \" \".join(cmd))\n",
    "with open(LOG, \"w\") as logf:\n",
    "    proc = subprocess.run(cmd, stdout=logf, stderr=subprocess.STDOUT, check=False)\n",
    "print(\"Return code:\", proc.returncode)\n",
    "assert DOMTBL.exists(), f\"domtblout not written: {DOMTBL}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse domtblout → domain table\n",
    "HMMER domtblout columns (subset used):\n",
    "1. `tname` (target/sequence ID), 2. `tacc`, 3. `tlen`, 4. `qname` (PF00010), 6. `qlen`, 7. `E-value (full)`, 8. `full score`, 13. `i-Evalue (dom)`, 14. `dom score`, 15–22: positions (`hmm_from/to`, `ali_from/to`, `env_from/to`), 23 `acc`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq_acc</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>query</th>\n",
       "      <th>query_acc</th>\n",
       "      <th>qlen</th>\n",
       "      <th>e_full</th>\n",
       "      <th>score_full</th>\n",
       "      <th>bias_full</th>\n",
       "      <th>hit_index</th>\n",
       "      <th>...</th>\n",
       "      <th>i_evalue</th>\n",
       "      <th>score_dom</th>\n",
       "      <th>bias_dom</th>\n",
       "      <th>hmm_from</th>\n",
       "      <th>hmm_to</th>\n",
       "      <th>ali_from</th>\n",
       "      <th>ali_to</th>\n",
       "      <th>env_from</th>\n",
       "      <th>env_to</th>\n",
       "      <th>acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hgra_g12400.t1</td>\n",
       "      <td>None</td>\n",
       "      <td>213</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>6.600000e-23</td>\n",
       "      <td>72.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.300000e-22</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>77</td>\n",
       "      <td>127</td>\n",
       "      <td>75</td>\n",
       "      <td>127</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abru_g15100.t1</td>\n",
       "      <td>None</td>\n",
       "      <td>195</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>3.800000e-22</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.300000e-22</td>\n",
       "      <td>69.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>76</td>\n",
       "      <td>126</td>\n",
       "      <td>74</td>\n",
       "      <td>126</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dsil_g4955.t1</td>\n",
       "      <td>None</td>\n",
       "      <td>248</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>4.300000e-22</td>\n",
       "      <td>70.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.600000e-22</td>\n",
       "      <td>69.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>101</td>\n",
       "      <td>151</td>\n",
       "      <td>99</td>\n",
       "      <td>151</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ptep_aug3.g15679</td>\n",
       "      <td>None</td>\n",
       "      <td>238</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>4.800000e-22</td>\n",
       "      <td>70.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.900000e-22</td>\n",
       "      <td>69.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>83</td>\n",
       "      <td>133</td>\n",
       "      <td>81</td>\n",
       "      <td>133</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ptep_aug3.g13882</td>\n",
       "      <td>None</td>\n",
       "      <td>210</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>8.900000e-22</td>\n",
       "      <td>69.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700000e-21</td>\n",
       "      <td>68.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>97</td>\n",
       "      <td>146</td>\n",
       "      <td>95</td>\n",
       "      <td>146</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             seq_id seq_acc  seq_len query   query_acc  qlen        e_full  \\\n",
       "0    Hgra_g12400.t1    None      213   HLH  PF00010.31    53  6.600000e-23   \n",
       "1    Abru_g15100.t1    None      195   HLH  PF00010.31    53  3.800000e-22   \n",
       "2     Dsil_g4955.t1    None      248   HLH  PF00010.31    53  4.300000e-22   \n",
       "3  Ptep_aug3.g15679    None      238   HLH  PF00010.31    53  4.800000e-22   \n",
       "4  Ptep_aug3.g13882    None      210   HLH  PF00010.31    53  8.900000e-22   \n",
       "\n",
       "   score_full  bias_full  hit_index  ...      i_evalue  score_dom  bias_dom  \\\n",
       "0        72.9        0.6          1  ...  1.300000e-22       72.0       0.6   \n",
       "1        70.5        0.5          1  ...  6.300000e-22       69.8       0.5   \n",
       "2        70.3        0.4          1  ...  6.600000e-22       69.7       0.4   \n",
       "3        70.2        0.5          1  ...  8.900000e-22       69.3       0.5   \n",
       "4        69.3        2.2          1  ...  1.700000e-21       68.4       2.2   \n",
       "\n",
       "   hmm_from  hmm_to  ali_from  ali_to  env_from  env_to   acc  \n",
       "0         3      53        77     127        75     127  0.97  \n",
       "1         3      53        76     126        74     126  0.97  \n",
       "2         3      53       101     151        99     151  0.97  \n",
       "3         3      53        83     133        81     133  0.97  \n",
       "4         4      53        97     146        95     146  0.98  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "\n",
    "def _to_int(x):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _to_float(x):\n",
    "    try:\n",
    "        if x == '-' or x is None:\n",
    "            return math.nan\n",
    "        return float(x)\n",
    "    except Exception:\n",
    "        return math.nan\n",
    "\n",
    "def read_domtbl(path):\n",
    "    # HMMER3 domtblout columns (per hmmer.org docs)\n",
    "    # 0 tname, 1 tacc, 2 tlen, 3 qname, 4 qacc, 5 qlen,\n",
    "    # 6 E-value, 7 score, 8 bias, 9 #, 10 of, 11 c-Evalue,\n",
    "    # 12 i-Evalue, 13 score_dom, 14 bias_dom,\n",
    "    # 15 hmm_from, 16 hmm_to, 17 ali_from, 18 ali_to,\n",
    "    # 19 env_from, 20 env_to, 21 acc\n",
    "    rows = []\n",
    "    with open(path) as fh:\n",
    "        for line in fh:\n",
    "            if not line or line.startswith('#'):\n",
    "                continue\n",
    "            # split on any whitespace, but only take the first 22 fields\n",
    "            parts = re.split(r'\\s+', line.strip())\n",
    "            if len(parts) < 22:\n",
    "                # some lines can be truncated; skip safely\n",
    "                continue\n",
    "            parts = parts[:22]\n",
    "\n",
    "            rows.append({\n",
    "                'seq_id'     : parts[0],\n",
    "                'seq_acc'    : None if parts[1] == '-' else parts[1],\n",
    "                'seq_len'    : _to_int(parts[2]),\n",
    "                'query'      : parts[3],\n",
    "                'query_acc'  : None if parts[4] == '-' else parts[4],\n",
    "                'qlen'       : _to_int(parts[5]),\n",
    "                'e_full'     : _to_float(parts[6]),\n",
    "                'score_full' : _to_float(parts[7]),\n",
    "                'bias_full'  : _to_float(parts[8]),\n",
    "                'hit_index'  : _to_int(parts[9]),      # domain number (#)\n",
    "                'hit_of'     : _to_int(parts[10]),     # total domains (of)\n",
    "                'c_evalue'   : _to_float(parts[11]),\n",
    "                'i_evalue'   : _to_float(parts[12]),\n",
    "                'score_dom'  : _to_float(parts[13]),\n",
    "                'bias_dom'   : _to_float(parts[14]),\n",
    "                'hmm_from'   : _to_int(parts[15]),\n",
    "                'hmm_to'     : _to_int(parts[16]),\n",
    "                'ali_from'   : _to_int(parts[17]),\n",
    "                'ali_to'     : _to_int(parts[18]),\n",
    "                'env_from'   : _to_int(parts[19]),\n",
    "                'env_to'     : _to_int(parts[20]),\n",
    "                'acc'        : _to_float(parts[21]),   # <-- correct index\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df = read_domtbl(DOMTBL)\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter hits and compute anchors\n",
    "- Keep domains where **full-seq E-value** ≤ `EVALUE_SEQ_MAX` and **domain i-Evalue** ≤ `EVALUE_DOM_MAX` and `score_dom` ≥ `MIN_DOM_SCORE`.\n",
    "- Define the **anchor** as the integer center of the target alignment: `floor((ali_from + ali_to)/2)`.\n",
    "- Keep multiple domains per sequence (bHLH duplications allowed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(89, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq_id</th>\n",
       "      <th>seq_acc</th>\n",
       "      <th>seq_len</th>\n",
       "      <th>query</th>\n",
       "      <th>query_acc</th>\n",
       "      <th>qlen</th>\n",
       "      <th>e_full</th>\n",
       "      <th>score_full</th>\n",
       "      <th>bias_full</th>\n",
       "      <th>hit_index</th>\n",
       "      <th>...</th>\n",
       "      <th>bias_dom</th>\n",
       "      <th>hmm_from</th>\n",
       "      <th>hmm_to</th>\n",
       "      <th>ali_from</th>\n",
       "      <th>ali_to</th>\n",
       "      <th>env_from</th>\n",
       "      <th>env_to</th>\n",
       "      <th>acc</th>\n",
       "      <th>dom_index</th>\n",
       "      <th>anchor_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Abru_g13702.t1</td>\n",
       "      <td>None</td>\n",
       "      <td>229</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>2.200000e-20</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>119</td>\n",
       "      <td>168</td>\n",
       "      <td>117</td>\n",
       "      <td>168</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Abru_g14616.t1</td>\n",
       "      <td>None</td>\n",
       "      <td>170</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>3.800000e-20</td>\n",
       "      <td>64.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>58</td>\n",
       "      <td>110</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Abru_g14798.t1</td>\n",
       "      <td>None</td>\n",
       "      <td>221</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>6.400000e-20</td>\n",
       "      <td>63.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>84</td>\n",
       "      <td>152</td>\n",
       "      <td>82</td>\n",
       "      <td>152</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Abru_g14799.t1</td>\n",
       "      <td>None</td>\n",
       "      <td>233</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>6.300000e-20</td>\n",
       "      <td>63.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>93</td>\n",
       "      <td>143</td>\n",
       "      <td>91</td>\n",
       "      <td>143</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Abru_g14800.t1</td>\n",
       "      <td>None</td>\n",
       "      <td>222</td>\n",
       "      <td>HLH</td>\n",
       "      <td>PF00010.31</td>\n",
       "      <td>53</td>\n",
       "      <td>1.400000e-20</td>\n",
       "      <td>65.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>112</td>\n",
       "      <td>162</td>\n",
       "      <td>110</td>\n",
       "      <td>162</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            seq_id seq_acc  seq_len query   query_acc  qlen        e_full  \\\n",
       "54  Abru_g13702.t1    None      229   HLH  PF00010.31    53  2.200000e-20   \n",
       "61  Abru_g14616.t1    None      170   HLH  PF00010.31    53  3.800000e-20   \n",
       "67  Abru_g14798.t1    None      221   HLH  PF00010.31    53  6.400000e-20   \n",
       "65  Abru_g14799.t1    None      233   HLH  PF00010.31    53  6.300000e-20   \n",
       "48  Abru_g14800.t1    None      222   HLH  PF00010.31    53  1.400000e-20   \n",
       "\n",
       "    score_full  bias_full  hit_index  ...  bias_dom  hmm_from  hmm_to  \\\n",
       "54        64.8        3.4          1  ...       3.4         4      53   \n",
       "61        64.1        0.6          1  ...       0.6         4      53   \n",
       "67        63.4        0.1          1  ...       0.1         3      53   \n",
       "65        63.4        1.0          1  ...       0.2         3      53   \n",
       "48        65.4        0.8          1  ...       0.8         3      53   \n",
       "\n",
       "    ali_from  ali_to  env_from  env_to   acc  dom_index  anchor_pos  \n",
       "54       119     168       117     168  0.98          1         143  \n",
       "61        60     110        58     110  0.96          1          85  \n",
       "67        84     152        82     152  0.97          1         118  \n",
       "65        93     143        91     143  0.97          1         118  \n",
       "48       112     162       110     162  0.97          1         137  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = df[(df['e_full'] <= EVALUE_SEQ_MAX) & (df['i_evalue'] <= EVALUE_DOM_MAX) & (df['score_dom'] >= MIN_DOM_SCORE)].copy()\n",
    "f['dom_index'] = f.groupby('seq_id').cumcount() + 1\n",
    "f['anchor_pos'] = ((f['ali_from'] + f['ali_to']) // 2).astype(int)\n",
    "f.sort_values(['seq_id','dom_index'], inplace=True)\n",
    "print(f.shape)\n",
    "f.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exports\n",
    "We write three outputs under `results/`:\n",
    "1. `bHLH_anchors.tsv` — tidy table for downstream analysis.\n",
    "2. `bHLH_anchors.gff3` — domains as GFF features (type=PF00010_bHLH).\n",
    "3. `bHLH_anchors.json` — lightweight JSON for UI/plotting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: /Users/gorkemdurmaz/Desktop/asc_project_10/results/bHLH_anchors.tsv\n",
      "Wrote: /Users/gorkemdurmaz/Desktop/asc_project_10/results/bHLH_anchors.gff3\n",
      "Wrote: /Users/gorkemdurmaz/Desktop/asc_project_10/results/bHLH_anchors.json\n"
     ]
    }
   ],
   "source": [
    "OUT_TSV  = OUT / \"bHLH_anchors.tsv\"\n",
    "OUT_GFF  = OUT / \"bHLH_anchors.gff3\"\n",
    "OUT_JSON = OUT / \"bHLH_anchors.json\"\n",
    "\n",
    "cols = ['seq_id','seq_len','dom_index','anchor_pos','ali_from','ali_to','env_from','env_to','i_evalue','score_dom','e_full','score_full','acc','hmm_from','hmm_to']\n",
    "f[cols].to_csv(OUT_TSV, sep='\\t', index=False)\n",
    "print(\"Wrote:\", OUT_TSV)\n",
    "\n",
    "with open(OUT_GFF, 'w') as gff:\n",
    "    gff.write(\"##gff-version 3\\n\")\n",
    "    for _, r in f.iterrows():\n",
    "        attrs = [\n",
    "            f\"ID={r.seq_id}.PF00010.{r.dom_index}\",\n",
    "            f\"Name=PF00010_bHLH\",\n",
    "            f\"DomIndex={r.dom_index}\",\n",
    "            f\"iE={r.i_evalue}\",\n",
    "            f\"DomScore={r.score_dom}\",\n",
    "            f\"Anchor={r.anchor_pos}\"\n",
    "        ]\n",
    "        gff.write(\"\\t\".join([\n",
    "            r.seq_id, \"HMMER\", \"PF00010_bHLH\",\n",
    "            str(int(r.ali_from)), str(int(r.ali_to)),\n",
    "            str(r.score_dom), \".\", \".\",\n",
    "            \";\".join(attrs)\n",
    "        ]) + \"\\n\")\n",
    "print(\"Wrote:\", OUT_GFF)\n",
    "\n",
    "with open(OUT_JSON, 'w') as jf:\n",
    "    jf.write(f.to_json(orient='records'))\n",
    "print(\"Wrote:\", OUT_JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "872d5fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/mg_w6dbd39q6th2fvghj7bt00000gn/T/ipykernel_2859/2334998977.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  weak.groupby(pd.cut(df['score_dom'], bins=[0,40,50,60,70,80,90,100])).size()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "score_dom\n",
       "(0, 40]      1\n",
       "(40, 50]     1\n",
       "(50, 60]     9\n",
       "(60, 70]     0\n",
       "(70, 80]     0\n",
       "(80, 90]     0\n",
       "(90, 100]    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weak = df.query('score_dom < 60 or i_evalue > 1.6e-05')\n",
    "weak.groupby(pd.cut(df['score_dom'], bins=[0,40,50,60,70,80,90,100])).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick sanity summaries\n",
    "How many sequences/domains were detected; distribution of anchor positions, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sequences with ≥1 bHLH:\", f['seq_id'].nunique(), \"of\", df['seq_id'].nunique(), \"total in domtblout\")\n",
    "dom_counts = f.groupby('seq_id')['dom_index'].max().describe()\n",
    "display(dom_counts)\n",
    "\n",
    "ax = f['anchor_pos'].plot(kind='hist', bins=40, title='Anchor positions (target AA index)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) write per-sequence anchor summary for MEME slicing later\n",
    "This creates a simple `seq_id → list of (start,end,anchor)` JSON that i can reuse if decide to slice windows around bHLH (even though the main analysis will use full-length sequences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "by_seq = defaultdict(list)\n",
    "for _, r in f.iterrows():\n",
    "    by_seq[r.seq_id].append({'start': int(r.ali_from), 'end': int(r.ali_to), 'anchor': int(r.anchor_pos), 'dom_index': int(r.dom_index)})\n",
    "ANCHORS_JSON = OUT / \"bHLH_anchors.by_seq.json\"\n",
    "import json\n",
    "with open(ANCHORS_JSON, 'w') as jf:\n",
    "    json.dump(by_seq, jf, indent=2)\n",
    "print(\"Wrote:\", ANCHORS_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What next?\n",
    "- Proceed to  MEME notebook to run **de‑novo motif discovery on full-length proteins**, optionally stratified by clade, now with reliable bHLH anchors for mapping/masking if needed.\n",
    "- For tree overlays in iTOL/ETE3, the `bHLH_anchors.tsv` provides consistent coordinates and domain counts per protein.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
