{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 · Motif post-processing & domain candidacy (ASC project)\n",
    "\n",
    "This notebook complements your FIMO pipeline with:\n",
    "- **TOMTOM clustering** of MEME motifs across clades\n",
    "- **Distance-to-bHLH** analysis per motif/cluster\n",
    "- **Cluster-level** specificity & enrichment (family/clade)\n",
    "- **Tree** (presence matrices, binary datasets)\n",
    "- **fimo plots** instead of tomtom clustering we used fimo results because it was more coherent\n",
    "\n",
    "\n",
    "\n",
    "**Assumptions**:\n",
    "- You already ran MEME (motifs per clade)\n",
    "- You ran FIMO (full-length scan, producing `_summaries`)\n",
    "- You have anchors in `results/bHLH_anchors.tsv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project: /Users/gorkemdurmaz/Desktop/asc_project_10\n",
      "Targets exist: True Anchors exist: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, re, json, math, shutil, subprocess, collections\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "# --- Project paths  ---\n",
    "PROJ = Path.cwd().resolve().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA = PROJ / \"data\"\n",
    "OUT  = PROJ / \"results\"\n",
    "CLADES = OUT / \"clades\"\n",
    "MOTIFS = OUT / \"motifs\"\n",
    "REPORTS = OUT / \"reports\"\n",
    "SUMDIR = MOTIFS / \"_summaries\"\n",
    "\n",
    "for d in (OUT, CLADES, MOTIFS, REPORTS, SUMDIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IN_TARGETS = DATA / \"ASC_targets.fasta\"\n",
    "BHLH_TSV   = OUT / \"bHLH_anchors.tsv\"\n",
    "\n",
    "norm_id = lambda x: re.sub(r\"[^A-Za-z0-9._-]+\",\"\", re.sub(r\"\\.(t?\\d+)$\",\"\", (x or \"\").split()[0].split(\"|\")[-1]))\n",
    "def nearest(vals, x):\n",
    "    if not vals: return (None, None)\n",
    "    arr = np.array(vals, dtype=int)\n",
    "    idx = int(np.argmin(np.abs(arr - x)))\n",
    "    return (int(arr[idx]), int(arr[idx] - x))\n",
    "\n",
    "print(\"Project:\", PROJ)\n",
    "print(\"Targets exist:\", IN_TARGETS.exists(), \"Anchors exist:\", BHLH_TSV.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28394b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using] NON_BHLH_SOFT.fimo_hits.filtered_perseq.tsv\n",
      "Rows with distances: 185 / 200\n"
     ]
    }
   ],
   "source": [
    "# --- AUTO-DETECT which summary tag to use \n",
    "# Prefer the strictest set (NON_BHLH_SOFT), else NON_BHLH, else ALL\n",
    "CANDIDATE_TAGS = [\"NON_BHLH_SOFT\", \"NON_BHLH\", \"ALL\"]\n",
    "avail = {tag: (SUMDIR / f\"{tag}.fimo_hits.filtered_perseq.tsv\").exists() for tag in CANDIDATE_TAGS}\n",
    "BASE_TAG = next((t for t in CANDIDATE_TAGS if avail.get(t)), None)\n",
    "if BASE_TAG is None:\n",
    "    raise SystemExit(\"No *_fimo_hits.filtered_perseq.tsv found in _summaries/.\")\n",
    "fam_hits_path = SUMDIR / f\"{BASE_TAG}.fimo_hits.filtered_perseq.tsv\"\n",
    "\n",
    "print(f\"[Using] {fam_hits_path.name}\")\n",
    "\n",
    "# --- Load and compute distance-to-bHLH \n",
    "anchors = pd.read_csv(BHLH_TSV, sep=\"\\t\")\n",
    "anchors[\"seq_norm\"] = anchors[\"seq_id\"].map(norm_id)\n",
    "by_seq_anchors = anchors.groupby(\"seq_norm\")[\"anchor_pos\"].apply(lambda s: sorted(set(map(int, s)))).to_dict()\n",
    "\n",
    "hits = pd.read_csv(fam_hits_path, sep=\"\\t\")\n",
    "# Expect these columns from your 4.2: sequence_name, source_clade, motif_id, start, stop, matched_sequence,\n",
    "# plus target_clade, target_family if the 4.2 saved them .\n",
    "hits[\"seq_norm\"]   = hits[\"sequence_name\"].map(norm_id)\n",
    "hits[\"hit_mid\"]    = ((hits[\"start\"] + hits[\"stop\"]) // 2).astype(\"Int64\")\n",
    "\n",
    "def nearest(vals, x):\n",
    "    if not vals: return (None, None)\n",
    "    arr = np.array(vals, dtype=int)\n",
    "    i = int(np.argmin(np.abs(arr - x)))\n",
    "    return int(arr[i]), int(arr[i] - x)\n",
    "\n",
    "nearest_anchor, delta = [], []\n",
    "for _, r in hits.iterrows():\n",
    "    mids = by_seq_anchors.get(r[\"seq_norm\"], [])\n",
    "    if pd.isna(r[\"hit_mid\"]) or not mids:\n",
    "        nearest_anchor.append(None); delta.append(None)\n",
    "    else:\n",
    "        na, d = nearest(mids, int(r[\"hit_mid\"]))\n",
    "        nearest_anchor.append(na); delta.append(d)\n",
    "\n",
    "hits[\"nearest_bHLH_anchor\"] = nearest_anchor\n",
    "hits[\"dist_from_bHLH\"]      = delta\n",
    "print(\"Rows with distances:\", hits[\"dist_from_bHLH\"].notna().sum(), \"/\", len(hits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b064b676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity tables saved: CLUSTERS.FAMILY.specificity.tsv CLUSTERS.CLADE.specificity.tsv\n"
     ]
    }
   ],
   "source": [
    "# Map each (source_clade|motif_id) to a cluster ID (TOMTOM may be absent — then each motif is its own cluster)\n",
    "hits[\"global_motif_id\"] = hits[\"source_clade\"] + \"|\" + hits[\"motif_id\"].astype(str)\n",
    "def motif_to_cluster(mid): \n",
    "    # If you ran TOMTOM and built cluster_id_of, it will map; otherwise each motif is its own cluster.\n",
    "    return cluster_id_of.get(mid, f\"SINGLE::{mid}\")\n",
    "hits[\"motif_cluster\"] = hits[\"global_motif_id\"].map(motif_to_cluster)\n",
    "\n",
    "def cluster_specificity_from_hits(df: pd.DataFrame, level: str):\n",
    "    \"\"\"\n",
    "    Compute specificity using the currently loaded hits table (no need for pre-saved FAMILY/CLADE files).\n",
    "    - level: 'family' or 'clade'\n",
    "    \"\"\"\n",
    "    if level == \"family\":\n",
    "        key = \"target_family\"\n",
    "        if key not in df.columns:\n",
    "            raise SystemExit(\"target_family column not found in hits. Re-run your 4.2 to include family mapping, or map it here.\")\n",
    "    else:\n",
    "        key = \"target_clade\"\n",
    "        if key not in df.columns:\n",
    "            raise SystemExit(\"target_clade column not found in hits. Re-run your 4.2 to include clade mapping, or map it here.\")\n",
    "\n",
    "    # Counts of unique sequences hit per bucket\n",
    "    counts = (df.groupby([\"motif_cluster\", key])\n",
    "                .agg(n_seq_hits=(\"seq_norm\", \"nunique\"))\n",
    "                .reset_index())\n",
    "\n",
    "    # Denominators: number of sequences per bucket present in this hits table\n",
    "    # (If you want denominators = all sequences per bucket, compute from CLADE FASTAs instead.)\n",
    "    denom = df[[\"seq_norm\", key]].drop_duplicates()[key].value_counts().to_dict()\n",
    "    total_mapped = sum(denom.values()) if denom else np.nan\n",
    "\n",
    "    counts[\"hit_rate\"] = counts.apply(lambda r: r.n_seq_hits / denom.get(r[key], np.nan), axis=1)\n",
    "    base = counts.groupby(\"motif_cluster\")[\"n_seq_hits\"].sum().rename(\"global_n_hits\").reset_index()\n",
    "    base[\"global_rate\"] = base[\"global_n_hits\"] / total_mapped if total_mapped else np.nan\n",
    "    spec = counts.merge(base, on=\"motif_cluster\", how=\"left\")\n",
    "    spec[\"enrichment\"] = spec[\"hit_rate\"] / spec[\"global_rate\"]\n",
    "    spec[\"log2_enrichment\"] = spec[\"enrichment\"].apply(lambda x: np.log2(x) if (pd.notna(x) and x > 0) else np.nan)\n",
    "    return spec\n",
    "\n",
    "spec_fam = cluster_specificity_from_hits(hits, \"family\")  # requires 'target_family' in hits\n",
    "spec_cla = cluster_specificity_from_hits(hits, \"clade\")   # requires 'target_clade'  in hits\n",
    "\n",
    "spec_fam.to_csv(SUMDIR / \"CLUSTERS.FAMILY.specificity.tsv\", sep=\"\\t\", index=False)\n",
    "spec_cla.to_csv(SUMDIR / \"CLUSTERS.CLADE.specificity.tsv\",  sep=\"\\t\", index=False)\n",
    "print(\"Specificity tables saved:\", \n",
    "      (SUMDIR / \"CLUSTERS.FAMILY.specificity.tsv\").name, \n",
    "      (SUMDIR / \"CLUSTERS.CLADE.specificity.tsv\").name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A) TOMTOM clustering of motifs across clades\n",
    "We cluster all MEME motifs (from every clade) using TOMTOM all-vs-all to group redundant motifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found MEME files: 10\n",
      "Wrote: /Users/gorkemdurmaz/Desktop/asc_project_10/results/motifs/_combined_all_memes.txt\n",
      "Running: tomtom -oc /Users/gorkemdurmaz/Desktop/asc_project_10/results/motifs/_tomtom_all -thresh 0.5 -min-overlap 5 /Users/gorkemdurmaz/Desktop/asc_project_10/results/motifs/_combined_all_memes.txt /Users/gorkemdurmaz/Desktop/asc_project_10/results/motifs/_combined_all_memes.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Target database size too small (8) for accurate p-value computation.\n",
      "Provide at least 50 motifs for accurate p-value computation.\n",
      "The output directory '/Users/gorkemdurmaz/Desktop/asc_project_10/results/motifs/_tomtom_all' already exists.\n",
      "Its contents will be overwritten.\n",
      "Processing query 1 out of 8 \n",
      "# Computing q-values.\n",
      "#   Cannot estimate pi_0 accurately from fewer than 100 p-values.\n",
      "#   Total p-values = 8. Using pi_zero = 1.0.\n",
      "Processing query 2 out of 8 \n",
      "# Computing q-values.\n",
      "#   Cannot estimate pi_0 accurately from fewer than 100 p-values.\n",
      "#   Total p-values = 8. Using pi_zero = 1.0.\n",
      "Processing query 3 out of 8 \n",
      "# Computing q-values.\n",
      "#   Cannot estimate pi_0 accurately from fewer than 100 p-values.\n",
      "#   Total p-values = 8. Using pi_zero = 1.0.\n",
      "Processing query 4 out of 8 \n",
      "# Computing q-values.\n",
      "#   Cannot estimate pi_0 accurately from fewer than 100 p-values.\n",
      "#   Total p-values = 8. Using pi_zero = 1.0.\n",
      "Processing query 5 out of 8 \n",
      "# Computing q-values.\n",
      "#   Cannot estimate pi_0 accurately from fewer than 100 p-values.\n",
      "#   Total p-values = 8. Using pi_zero = 1.0.\n",
      "Processing query 6 out of 8 \n",
      "# Computing q-values.\n",
      "#   Cannot estimate pi_0 accurately from fewer than 100 p-values.\n",
      "#   Total p-values = 8. Using pi_zero = 1.0.\n",
      "Processing query 7 out of 8 \n",
      "# Computing q-values.\n",
      "#   Cannot estimate pi_0 accurately from fewer than 100 p-values.\n",
      "#   Total p-values = 8. Using pi_zero = 1.0.\n",
      "Processing query 8 out of 8 \n",
      "# Computing q-values.\n",
      "#   Cannot estimate pi_0 accurately from fewer than 100 p-values.\n",
      "#   Total p-values = 8. Using pi_zero = 1.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOMTOM done -> /Users/gorkemdurmaz/Desktop/asc_project_10/results/motifs/_tomtom_all\n",
      "TOMTOM skipped — each motif treated as own cluster.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "meme_paths = sorted([p for p in MOTIFS.glob(\"*/meme_out/meme.txt\") if p.is_file()])\n",
    "print(\"Found MEME files:\", len(meme_paths))\n",
    "\n",
    "if shutil.which(\"tomtom\") is None:\n",
    "    print(\"WARNING: 'tomtom' not found on PATH. Skipping TOMTOM clustering section.\")\n",
    "    TOMTOM_AVAILABLE = False\n",
    "else:\n",
    "    TOMTOM_AVAILABLE = True\n",
    "\n",
    "COMBINED_MEME = MOTIFS / \"_combined_all_memes.txt\"\n",
    "if TOMTOM_AVAILABLE:\n",
    "    with open(COMBINED_MEME, \"w\") as out:\n",
    "        for mp in meme_paths:\n",
    "            out.write(open(mp).read())\n",
    "    print(\"Wrote:\", COMBINED_MEME)\n",
    "\n",
    "TOMDIR = MOTIFS / \"_tomtom_all\"\n",
    "if TOMTOM_AVAILABLE:\n",
    "    if TOMDIR.exists(): shutil.rmtree(TOMDIR)\n",
    "    TOMDIR.mkdir(parents=True, exist_ok=True)\n",
    "    cmd = [\"tomtom\", \"-oc\", str(TOMDIR), \"-thresh\", \"0.5\", \"-min-overlap\", \"5\", str(COMBINED_MEME), str(COMBINED_MEME)]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=False)\n",
    "    print(\"TOMTOM done ->\", TOMDIR)\n",
    "\n",
    "cluster_id_of = {}\n",
    "members = collections.defaultdict(set)\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "except ImportError:\n",
    "    nx = None\n",
    "\n",
    "if TOMTOM_AVAILABLE and nx and (TOMDIR / \"tomtom.tsv\").exists():\n",
    "    tt = pd.read_csv(TOMDIR / \"tomtom.tsv\", sep=\"\\t\", comment=\"#\")\n",
    "    tt = tt[tt.get(\"q-value\", tt.get(\"p-value\", 1)).fillna(1) <= 0.1]\n",
    "    G = nx.Graph()\n",
    "    for _, r in tt.iterrows():\n",
    "        G.add_edge(str(r[\"Query_ID\"]), str(r[\"Target_ID\"]))\n",
    "    for i, comp in enumerate(nx.connected_components(G), 1):\n",
    "        cid = f\"MTFCL_{i:04d}\"\n",
    "        for m in comp:\n",
    "            cluster_id_of[m] = cid\n",
    "            members[cid].add(m)\n",
    "    print(\"TOMTOM clusters:\", len(members))\n",
    "else:\n",
    "    print(\"TOMTOM skipped — each motif treated as own cluster.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Load FIMO results and compute distance-to-bHLH\n",
    "Attach nearest bHLH anchor and compute `dist_from_bHLH` for each hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using FIMO hits] NON_BHLH_SOFT.fimo_hits.filtered_perseq.tsv\n",
      "Rows with distances: 185 / 200  (tag=NON_BHLH_SOFT)\n"
     ]
    }
   ],
   "source": [
    "# --- Robust distance-to-bHLH computation (works with  _summaries filenames) \n",
    "import re, numpy as np, pandas as pd\n",
    "\n",
    "# Helpers\n",
    "norm_id = lambda x: re.sub(r\"[^A-Za-z0-9._-]+\",\"\", re.sub(r\"\\.(t?\\d+)$\",\"\", (str(x) or \"\").split()[0].split(\"|\")[-1]))\n",
    "def nearest(vals, x):\n",
    "    \"\"\"Return (nearest_value, delta = nearest_value - x) or (None, None) if vals empty.\"\"\"\n",
    "    if not vals:\n",
    "        return (None, None)\n",
    "    arr = np.array(vals, dtype=int)\n",
    "    i = int(np.argmin(np.abs(arr - x)))\n",
    "    return int(arr[i]), int(arr[i] - x)\n",
    "\n",
    "# 1) Load anchors\n",
    "if not BHLH_TSV.exists():\n",
    "    raise SystemExit(f\"Missing anchors file: {BHLH_TSV}\")\n",
    "\n",
    "anchors = pd.read_csv(BHLH_TSV, sep=\"\\t\")\n",
    "required_anchor_cols = {\"seq_id\", \"anchor_pos\", \"ali_from\", \"ali_to\"}\n",
    "missing_anchor = required_anchor_cols - set(anchors.columns)\n",
    "if missing_anchor:\n",
    "    raise SystemExit(f\"Anchors file missing required columns: {missing_anchor}\")\n",
    "\n",
    "anchors[\"seq_norm\"] = anchors[\"seq_id\"].map(norm_id)\n",
    "# Use unique, sorted anchor positions per sequence\n",
    "by_seq_anchors = (anchors\n",
    "                  .assign(anchor_pos=pd.to_numeric(anchors[\"anchor_pos\"], errors=\"coerce\"))\n",
    "                  .dropna(subset=[\"anchor_pos\"])\n",
    "                  .groupby(\"seq_norm\")[\"anchor_pos\"]\n",
    "                  .apply(lambda s: sorted(set(int(v) for v in s)))\n",
    "                  .to_dict())\n",
    "\n",
    "# 2) Auto-detect which hits table to use (prefer strictest set)\n",
    "CANDIDATE_TAGS = [\"NON_BHLH_SOFT\", \"NON_BHLH\", \"ALL\"]\n",
    "existing = [tag for tag in CANDIDATE_TAGS if (SUMDIR / f\"{tag}.fimo_hits.filtered_perseq.tsv\").exists()]\n",
    "if not existing:\n",
    "    raise SystemExit(f\"No *_fimo_hits.filtered_perseq.tsv found in {SUMDIR}\")\n",
    "BASE_TAG = existing[0]  # pick first available in priority order\n",
    "fam_hits_path = SUMDIR / f\"{BASE_TAG}.fimo_hits.filtered_perseq.tsv\"\n",
    "print(f\"[Using FIMO hits] {fam_hits_path.name}\")\n",
    "\n",
    "# 3) Load hits & sanity checks\n",
    "hits = pd.read_csv(fam_hits_path, sep=\"\\t\")\n",
    "# Expect these columns from your 4.2 outputs (some may use slightly different names)\n",
    "needed = {\"sequence_name\", \"source_clade\", \"motif_id\", \"start\", \"stop\", \"matched_sequence\"}\n",
    "missing = needed - set(hits.columns)\n",
    "if missing:\n",
    "    # Try common alternates (rare)\n",
    "    rename_map = {}\n",
    "    if \"motif_ID\" in missing and \"motif_ID\" in hits.columns: rename_map[\"motif_ID\"] = \"motif_id\"\n",
    "    if rename_map:\n",
    "        hits = hits.rename(columns=rename_map)\n",
    "        missing = needed - set(hits.columns)\n",
    "if missing:\n",
    "    raise SystemExit(f\"Hits table missing required columns: {missing}\")\n",
    "\n",
    "# 4) Normalize IDs & coerce numeric\n",
    "hits[\"seq_norm\"] = hits[\"sequence_name\"].map(norm_id)\n",
    "for c in (\"start\", \"stop\"):\n",
    "    hits[c] = pd.to_numeric(hits[c], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# 5) Compute hit midpoints safely\n",
    "hits[\"hit_mid\"] = ((hits[\"start\"].astype(\"float\") + hits[\"stop\"].astype(\"float\")) / 2.0).round().astype(\"Int64\")\n",
    "\n",
    "# 6) Compute nearest bHLH anchor & distance\n",
    "nearest_anchor, delta = [], []\n",
    "for _, r in hits.iterrows():\n",
    "    mids = by_seq_anchors.get(r[\"seq_norm\"], [])\n",
    "    hm = r[\"hit_mid\"]\n",
    "    if pd.isna(hm) or not mids:\n",
    "        nearest_anchor.append(None); delta.append(None)\n",
    "    else:\n",
    "        na, d = nearest(mids, int(hm))\n",
    "        nearest_anchor.append(na); delta.append(d)\n",
    "\n",
    "hits[\"nearest_bHLH_anchor\"] = pd.array(nearest_anchor, dtype=\"Int64\")\n",
    "hits[\"dist_from_bHLH\"]      = pd.array(delta, dtype=\"Int64\")\n",
    "\n",
    "# 7) Report\n",
    "n_with = hits[\"dist_from_bHLH\"].notna().sum()\n",
    "print(f\"Rows with distances: {n_with} / {len(hits)}  (tag={BASE_TAG})\")\n",
    "\n",
    "# (optional) keep only rows with valid distances\n",
    "# hits = hits[hits[\"dist_from_bHLH\"].notna()].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C) Map motifs to clusters and recompute family/clade specificity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity tables saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hits[\"global_motif_id\"] = hits[\"source_clade\"] + \"|\" + hits[\"motif_id\"].astype(str)\n",
    "def motif_to_cluster(mid): return cluster_id_of.get(mid, f\"SINGLE::{mid}\")\n",
    "hits[\"motif_cluster\"] = hits[\"global_motif_id\"].map(motif_to_cluster)\n",
    "\n",
    "def cluster_specificity(df, level):\n",
    "    key = \"target_family\" if level == \"family\" else \"target_clade\"\n",
    "    counts = df.groupby([\"motif_cluster\", key]).agg(n_seq_hits=(\"seq_norm\", \"nunique\")).reset_index()\n",
    "    sizes = {}\n",
    "    src = SUMDIR / f\"ALL.{level.upper()}.fimo_hits.filtered_perseq.tsv\"\n",
    "    if src.exists():\n",
    "        amap = pd.read_csv(src, sep=\"\\t\")[[\"seq_norm\", key]].drop_duplicates()\n",
    "        sizes = amap[key].value_counts().to_dict()\n",
    "    total = sum(sizes.values()) if sizes else np.nan\n",
    "    counts[\"hit_rate\"] = counts.apply(lambda r: r.n_seq_hits / sizes.get(r[key], np.nan), axis=1)\n",
    "    base = counts.groupby(\"motif_cluster\")[\"n_seq_hits\"].sum().rename(\"global_n_hits\").reset_index()\n",
    "    base[\"global_rate\"] = base[\"global_n_hits\"] / total if total else np.nan\n",
    "    spec = counts.merge(base, on=\"motif_cluster\", how=\"left\")\n",
    "    spec[\"enrichment\"] = spec[\"hit_rate\"] / spec[\"global_rate\"]\n",
    "    spec[\"log2_enrichment\"] = spec[\"enrichment\"].apply(lambda x: np.log2(x) if pd.notna(x) and x > 0 else np.nan)\n",
    "    return spec\n",
    "\n",
    "spec_fam = cluster_specificity(hits, \"family\")\n",
    "spec_cla = cluster_specificity(hits, \"clade\")\n",
    "spec_fam.to_csv(SUMDIR / \"CLUSTERS.FAMILY.specificity.tsv\", sep=\"\\t\", index=False)\n",
    "spec_cla.to_csv(SUMDIR / \"CLUSTERS.CLADE.specificity.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"Specificity tables saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) Shortlist cluster-level candidates and compute positional stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortlist written.\n",
      "Position stats written.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n",
      "/Users/gorkemdurmaz/miniconda3/envs/asc/lib/python3.10/site-packages/numpy/lib/_nanfunctions_impl.py:1409: RuntimeWarning: All-NaN slice encountered\n",
      "  return _nanquantile_unchecked(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def family_cluster_shortlist(spec_fam, min_hits=3, min_log2_enrich=1.0):\n",
    "    fams = [\"ASCa\",\"ASCb\",\"ASCc\"]\n",
    "    pivot = (spec_fam[spec_fam[\"target_family\"].isin(fams)]\n",
    "             .pivot_table(index=\"motif_cluster\", columns=\"target_family\", values=\"n_seq_hits\", fill_value=0)\n",
    "             .reset_index())\n",
    "    for f in fams:\n",
    "        if f not in pivot.columns: pivot[f] = 0\n",
    "    pivot[\"dominant_family\"] = pivot[fams].idxmax(axis=1)\n",
    "    pivot[\"dominant_hits\"] = pivot[fams].max(axis=1)\n",
    "    enr = spec_fam.groupby([\"motif_cluster\",\"target_family\"])[\"log2_enrichment\"].max().unstack(fill_value=np.nan)\n",
    "    pivot = pivot.merge(enr, left_on=\"motif_cluster\", right_index=True, how=\"left\")\n",
    "    pivot[\"dominant_log2_enrichment\"] = pivot.apply(lambda r: r.get(r[\"dominant_family\"], np.nan), axis=1)\n",
    "    keep = (pivot[\"dominant_hits\"] >= min_hits) & (pivot[\"dominant_log2_enrichment\"] >= min_log2_enrich)\n",
    "    return pivot[keep].sort_values(\"dominant_hits\", ascending=False)\n",
    "\n",
    "cluster_shortlist = family_cluster_shortlist(spec_fam)\n",
    "cluster_shortlist.to_csv(SUMDIR / \"CLUSTERS.family_shortlist.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"Shortlist written.\")\n",
    "\n",
    "pos_stats = (hits.groupby(\"motif_cluster\")[\"dist_from_bHLH\"]\n",
    "             .agg(n=\"count\", median=\"median\", iqr=lambda s: np.nanpercentile(s,75)-np.nanpercentile(s,25) if len(s)>0 else np.nan)\n",
    "             .reset_index())\n",
    "pos_stats.to_csv(SUMDIR / \"CLUSTERS.position_stats.tsv\", sep=\"\\t\", index=False)\n",
    "print(\"Position stats written.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E) Tree visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Match] 76 / 76 matrix rows matched to tree tips\n",
      "Wrote: results/ASC_tree_with_motifs_circular.png\n",
      "Wrote: results/ASC_tree_with_motifs_circular.svg\n"
     ]
    }
   ],
   "source": [
    "# Robust ETE3 plotting of motif presence next to your ASC tree — CIRCULAR (start at top)\n",
    "\n",
    "from ete3 import Tree, TreeStyle, faces, TextFace\n",
    "import pandas as pd, numpy as np, re, math\n",
    "from pathlib import Path\n",
    "\n",
    "TREE   = Path(\"data/ASC-tree.newick\")\n",
    "MATRIX = Path(\"results/motifs/_summaries/NON_BHLH_SOFT.motif_presence_matrix.fixed_ids.tsv\")\n",
    "OUTPNG = Path(\"results/ASC_tree_with_motifs_circular.png\")\n",
    "OUTSVG = Path(\"results/ASC_tree_with_motifs_circular.svg\")   # vector for paper\n",
    "\n",
    "# ---------- Load ----------\n",
    "tree = Tree(str(TREE), format=1)\n",
    "mat  = pd.read_csv(MATRIX, sep=\"\\t\", index_col=0)\n",
    "\n",
    "# ---------- Normalize names so matrix rows match tree leaves ----------\n",
    "leaf_names = [n.name for n in tree.get_leaves()]\n",
    "\n",
    "def norm_id(x):\n",
    "    s = str(x)\n",
    "    s = re.sub(r\"\\s.*$\", \"\", s)         # strip after first whitespace\n",
    "    s = re.sub(r\"\\|.*$\", \"\", s)         # strip after first pipe\n",
    "    s = re.sub(r\"\\.(t|iso)?\\d+$\", \"\", s)  # drop trailing .t1 / .iso2 / .1\n",
    "    return s\n",
    "\n",
    "leaf_set = set(leaf_names)\n",
    "row_map, hits = {}, 0\n",
    "for rid in mat.index:\n",
    "    candidates = [rid, norm_id(rid)]\n",
    "    candidates += [c + \".t1\" for c in candidates]\n",
    "    m = next((c for c in candidates if c in leaf_set), None)\n",
    "    if m is not None:\n",
    "        row_map[rid] = m\n",
    "        hits += 1\n",
    "print(f\"[Match] {hits} / {len(mat)} matrix rows matched to tree tips\")\n",
    "\n",
    "mat2 = mat.loc[[r for r in mat.index if r in row_map]].copy()\n",
    "mat2.index = [row_map[r] for r in mat2.index]\n",
    "mat2 = mat2.reindex(leaf_names).fillna(0).astype(int)\n",
    "\n",
    "# ---------- Choose motif columns ----------\n",
    "TOP_N = 20\n",
    "col_counts   = mat2.sum(axis=0).sort_values(ascending=False)\n",
    "cols_to_show = list(col_counts.head(TOP_N).index)\n",
    "if len(cols_to_show) == 0:\n",
    "    raise SystemExit(\"No motif columns to show (all-zero matrix after matching?).\")\n",
    "mat_show = mat2[cols_to_show]\n",
    "\n",
    "# --- Prune tips with no motifs in the shown columns ---\n",
    "rows_with_any = mat_show.sum(axis=1) > 0\n",
    "keep_leaves = set(mat_show.index[rows_with_any])\n",
    "if len(keep_leaves) == 0:\n",
    "    raise SystemExit(\"All tips have zero motifs in the selected columns; nothing to plot.\")\n",
    "tree.prune(keep_leaves, preserve_branch_length=True)\n",
    "\n",
    "# Reindex matrix to the *new* leaf order and drop now-empty motif columns\n",
    "leaf_names = [n.name for n in tree.get_leaves()]\n",
    "mat_show = mat_show.loc[leaf_names]\n",
    "nonempty_cols = mat_show.sum(axis=0) > 0\n",
    "mat_show = mat_show.loc[:, nonempty_cols]\n",
    "\n",
    "# ---------- Colors (define AFTER pruning so it matches final columns) ----------\n",
    "def distinct_colors(n):\n",
    "    out = []\n",
    "    for i in range(n):\n",
    "        h = i / max(1, n); s, l = 0.60, 0.55\n",
    "        def hue2rgb(p, q, t):\n",
    "            if t < 0: t += 1\n",
    "            if t > 1: t -= 1\n",
    "            if t < 1/6: return p + (q - p) * 6 * t\n",
    "            if t < 1/2: return q\n",
    "            if t < 2/3: return p + (q - p) * (2/3 - t) * 6\n",
    "            return p\n",
    "        q = l + s - l * s; p = 2 * l - q\n",
    "        r = hue2rgb(p, q, h + 1/3); g = hue2rgb(p, q, h); b = hue2rgb(p, q, h - 1/3)\n",
    "        out.append('#%02x%02x%02x' % (int(r*255), int(g*255), int(b*255)))\n",
    "    return out\n",
    "\n",
    "motif_colors = dict(zip(list(mat_show.columns), distinct_colors(mat_show.shape[1])))\n",
    "\n",
    "# ---------- Layout with small boxes per present motif ----------\n",
    "BOX_W, BOX_H = 8, 8\n",
    "\n",
    "def layout(node):\n",
    "    if node.is_leaf():\n",
    "        row = mat_show.loc[node.name]\n",
    "        faces.add_face_to_node(TextFace(node.name, fsize=12), node, column=-1, position=\"aligned\")\n",
    "        col_idx = 0\n",
    "        for motif, present in row.items():\n",
    "            if present == 1:\n",
    "                box = faces.RectFace(width=BOX_W, height=BOX_H, fgcolor=\"black\", bgcolor=motif_colors[motif])\n",
    "            else:\n",
    "                box = faces.RectFace(width=BOX_W, height=BOX_H, fgcolor=None, bgcolor=None)\n",
    "            faces.add_face_to_node(box, node, column=col_idx, position=\"aligned\")\n",
    "            col_idx += 1\n",
    "\n",
    "# ---------- Tree style (CIRCULAR) ----------\n",
    "ts = TreeStyle()\n",
    "ts.mode = \"c\"                 # circular\n",
    "ts.arc_start = -90            # <<< start at TOP: x=0, y>0\n",
    "ts.arc_span  = 360            # full circle\n",
    "ts.min_leaf_separation = 8\n",
    "ts.show_leaf_name = False     # we render our own (smaller) names in layout()\n",
    "ts.show_scale = False\n",
    "ts.layout_fn = layout\n",
    "ts.margin_left = ts.margin_right = ts.margin_top = ts.margin_bottom = 15\n",
    "\n",
    "# Optional: cleaner look (no node circles)\n",
    "for n in tree.traverse():\n",
    "    n.img_style[\"size\"] = 0\n",
    "\n",
    "# ---------- Legend ----------\n",
    "try:\n",
    "    ts.legend._faces = []\n",
    "except Exception:\n",
    "    pass\n",
    "for motif, color in motif_colors.items():\n",
    "    ts.legend.add_face(faces.RectFace(width=14, height=14, fgcolor=\"black\", bgcolor=color), column=0)\n",
    "    ts.legend.add_face(TextFace(\"  \" + motif, fsize=13), column=1)\n",
    "\n",
    "# ---------- Render ----------\n",
    "OUTPNG.parent.mkdir(parents=True, exist_ok=True)\n",
    "tree.render(str(OUTPNG), tree_style=ts, w=3000, units=\"px\", dpi=300)\n",
    "tree.render(str(OUTSVG), tree_style=ts, w=2000, units=\"px\")\n",
    "print(\"Wrote:\", OUTPNG)\n",
    "print(\"Wrote:\", OUTSVG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d0a222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strict :  0 motifs  → ASC_motif_clusters.strict_candidates.tsv\n",
      "medium :  0 motifs  → ASC_motif_clusters.medium_candidates.tsv\n",
      "loose  : 27 motifs  → ASC_motif_clusters.loose_candidates.tsv\n",
      "\n",
      "Top-ranked motifs by enrichment & hits:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>motif_cluster</th>\n",
       "      <th>dominant_family</th>\n",
       "      <th>dominant_hits</th>\n",
       "      <th>dominant_log2_enrichment</th>\n",
       "      <th>pos_IQR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SINGLE::ASCb|KKDPFSPRCKIPLPTPFSPYEY</td>\n",
       "      <td>ASCb</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SINGLE::ASCc|VNKENELHQRW</td>\n",
       "      <td>ASCc</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SINGLE::ASCc|GCDDNYNPYLPFYDDYGGAL</td>\n",
       "      <td>ASCc</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_E|EASSPYDALHGDEEEELMD...</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SINGLE::ASCb|KMPEYTMLTPLPLTPDVMSHDFEQ</td>\n",
       "      <td>ASCb</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_A|EYPFDGSTEMIMPYG</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_A|PQGYRCDFGCPCNEG</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_E|QRIAPKLPHH</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SINGLE::ASCb|CELVPHYSFVNMVPP</td>\n",
       "      <td>ASCb</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SINGLE::ASCb|EEEEDDDDDDDGAGLSGCSNNS</td>\n",
       "      <td>ASCb</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SINGLE::ASH|YDNYEPKSPEDEEJLDYISLWQZ</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_A|MEMFPHQDYPPQNS</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_C|HRFMASHEDARRLLYL</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_C|QHTQDDQLMDIGLWFS</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_C|SGPAGGSGDLSPASSHPSD...</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_C|YGQDDCSSVASSEEI</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_D|DENDDFFBIMDWTTL</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_D|PPTHKLLLPLDRVGV</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_E|DENSYPVGGQSSTGSPTPSLCS</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SINGLE::ASCa_TrueSpiders_E|QQDNQDLLRCKRRIQLGHL...</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        motif_cluster dominant_family  \\\n",
       "24                SINGLE::ASCb|KKDPFSPRCKIPLPTPFSPYEY            ASCb   \n",
       "32                           SINGLE::ASCc|VNKENELHQRW            ASCc   \n",
       "28                  SINGLE::ASCc|GCDDNYNPYLPFYDDYGGAL            ASCc   \n",
       "18  SINGLE::ASCa_TrueSpiders_E|EASSPYDALHGDEEEELMD...            ASCa   \n",
       "25              SINGLE::ASCb|KMPEYTMLTPLPLTPDVMSHDFEQ            ASCb   \n",
       "0          SINGLE::ASCa_TrueSpiders_A|EYPFDGSTEMIMPYG            ASCa   \n",
       "3          SINGLE::ASCa_TrueSpiders_A|PQGYRCDFGCPCNEG            ASCa   \n",
       "21              SINGLE::ASCa_TrueSpiders_E|QRIAPKLPHH            ASCa   \n",
       "22                       SINGLE::ASCb|CELVPHYSFVNMVPP            ASCb   \n",
       "23                SINGLE::ASCb|EEEEDDDDDDDGAGLSGCSNNS            ASCb   \n",
       "34                SINGLE::ASH|YDNYEPKSPEDEEJLDYISLWQZ            ASCa   \n",
       "2           SINGLE::ASCa_TrueSpiders_A|MEMFPHQDYPPQNS            ASCa   \n",
       "7         SINGLE::ASCa_TrueSpiders_C|HRFMASHEDARRLLYL            ASCa   \n",
       "9         SINGLE::ASCa_TrueSpiders_C|QHTQDDQLMDIGLWFS            ASCa   \n",
       "10  SINGLE::ASCa_TrueSpiders_C|SGPAGGSGDLSPASSHPSD...            ASCa   \n",
       "11         SINGLE::ASCa_TrueSpiders_C|YGQDDCSSVASSEEI            ASCa   \n",
       "12         SINGLE::ASCa_TrueSpiders_D|DENDDFFBIMDWTTL            ASCa   \n",
       "14         SINGLE::ASCa_TrueSpiders_D|PPTHKLLLPLDRVGV            ASCa   \n",
       "17  SINGLE::ASCa_TrueSpiders_E|DENSYPVGGQSSTGSPTPSLCS            ASCa   \n",
       "20  SINGLE::ASCa_TrueSpiders_E|QQDNQDLLRCKRRIQLGHL...            ASCa   \n",
       "\n",
       "    dominant_hits  dominant_log2_enrichment  pos_IQR  \n",
       "24             14                       0.0     2.75  \n",
       "32             13                       0.0    26.00  \n",
       "28              9                       0.0    23.00  \n",
       "18              8                       0.0    35.25  \n",
       "25              8                       0.0    15.75  \n",
       "0               6                       0.0     1.00  \n",
       "3               6                       0.0     0.00  \n",
       "21              6                       0.0     4.00  \n",
       "22              6                       0.0    10.75  \n",
       "23              6                       0.0    45.25  \n",
       "34              6                       0.0    72.00  \n",
       "2               5                       0.0     3.00  \n",
       "7               5                       0.0     0.00  \n",
       "9               5                       0.0    19.75  \n",
       "10              5                       0.0     8.00  \n",
       "11              5                       0.0     6.00  \n",
       "12              5                       0.0     2.00  \n",
       "14              5                       0.0     2.00  \n",
       "17              5                       0.0     1.00  \n",
       "20              5                       0.0     0.75  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Relaxed candidate extraction ---\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "PROJ = Path.cwd().resolve().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "REPORT = PROJ / \"results\" / \"reports\"\n",
    "f = REPORT / \"ASC_motif_clusters.all.tsv\"\n",
    "df = pd.read_csv(f, sep=\"\\t\")\n",
    "\n",
    "# Handle missing data\n",
    "df[\"dominant_log2_enrichment\"] = pd.to_numeric(df[\"dominant_log2_enrichment\"], errors=\"coerce\").fillna(0)\n",
    "df[\"dominant_hits\"] = pd.to_numeric(df[\"dominant_hits\"], errors=\"coerce\").fillna(0)\n",
    "df[\"pos_IQR\"] = pd.to_numeric(df[\"pos_IQR\"], errors=\"coerce\").fillna(999)\n",
    "df[\"is_family_specific\"] = df[\"is_family_specific\"].astype(bool)\n",
    "\n",
    "# Define three thresholds\n",
    "criteria = {\n",
    "    \"strict\":  (df[\"dominant_hits\"]>=3) & (df[\"dominant_log2_enrichment\"]>=1.0) & (df[\"pos_IQR\"]<=50) & (df[\"is_family_specific\"]),\n",
    "    \"medium\":  (df[\"dominant_hits\"]>=2) & (df[\"dominant_log2_enrichment\"]>=0.5) & (df[\"pos_IQR\"]<=100),\n",
    "    \"loose\":   (df[\"dominant_hits\"]>=1) & (df[\"dominant_log2_enrichment\"]>=0) & (df[\"pos_IQR\"]<=200),\n",
    "}\n",
    "\n",
    "# Save filtered lists\n",
    "for name, cond in criteria.items():\n",
    "    out = REPORT / f\"ASC_motif_clusters.{name}_candidates.tsv\"\n",
    "    df[cond].sort_values([\"dominant_log2_enrichment\",\"dominant_hits\"], ascending=[False,False]).to_csv(out, sep=\"\\t\", index=False)\n",
    "    print(f\"{name:7s}: {cond.sum():2d} motifs  → {out.name}\")\n",
    "\n",
    "# Also produce a simple ranked top-20 view\n",
    "top = df.sort_values([\"dominant_log2_enrichment\",\"dominant_hits\"], ascending=[False,False]).head(20)\n",
    "print(\"\\nTop-ranked motifs by enrichment & hits:\\n\")\n",
    "display(top[[\"motif_cluster\",\"dominant_family\",\"dominant_hits\",\"dominant_log2_enrichment\",\"pos_IQR\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7658d",
   "metadata": {},
   "source": [
    "# PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d13d4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT WITH CLUSTER NAMES\n",
    "# === ASC domain architecture: correct MEME-# → CONSENSUS bridge, strict Tomtom RBH, robust anchors, top-K hits ===\n",
    "import pandas as pd, numpy as np, re\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict, deque\n",
    "\n",
    "# -------- knobs --------\n",
    "CLUSTER_MODE   = \"strict\"   # \"strict\" (RBH clusters on consensus) or \"none\" (color per PWM)\n",
    "Q_MAX          = 0.05       # Tomtom q-value cutoff (if present)\n",
    "P_MAX          = 1e-4       # Tomtom p-value cutoff (fallback if q missing)\n",
    "MIN_OVERLAP    = 8          # Tomtom min overlap\n",
    "TOP_K          = 3          # keep up to K non-overlapping sites per sequence\n",
    "NONOVERLAP_PAD = 6          # minimal gap (aa) between kept sites\n",
    "# -----------------------\n",
    "\n",
    "# Project layout\n",
    "PROJ = Path.cwd().resolve().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "DATA = PROJ / \"data\"\n",
    "OUT  = PROJ / \"results\"\n",
    "MOTIFS = OUT / \"motifs\"\n",
    "SUM   = MOTIFS / \"_summaries\"\n",
    "REPORT= OUT / \"reports\"\n",
    "REPORT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Inputs\n",
    "HITS_PATH = next((p for p in [\n",
    "    SUM / \"NON_BHLH_SOFT.fimo_hits.filtered_perseq.tsv\",\n",
    "    SUM / \"NON_BHLH.fimo_hits.filtered_perseq.tsv\",\n",
    "    SUM / \"ALL.fimo_hits.filtered_perseq.tsv\",\n",
    "] if p.exists()), None)\n",
    "if HITS_PATH is None:\n",
    "    raise SystemExit(\"No *fimo_hits.filtered_perseq.tsv found under _summaries/\")\n",
    "\n",
    "TOMTOM_TSV = MOTIFS / \"_tomtom_all\" / \"tomtom.tsv\"\n",
    "if not TOMTOM_TSV.exists():\n",
    "    alt = Path(\"tomtom.tsv\")\n",
    "    if alt.exists(): TOMTOM_TSV = alt\n",
    "if not TOMTOM_TSV.exists():\n",
    "    raise SystemExit(\"tomtom.tsv not found.\")\n",
    "\n",
    "COMBINED_MEME = MOTIFS / \"_combined_all_memes.txt\"\n",
    "ANCHORS_PATH  = OUT / \"bHLH_anchors.tsv\"\n",
    "TARGETS_FASTA = DATA / \"ASC_targets.fasta\"\n",
    "\n",
    "print(\"[hits]   \", HITS_PATH)\n",
    "print(\"[tomtom] \", TOMTOM_TSV)\n",
    "print(\"[meme]   \", COMBINED_MEME, \"(exists:\", COMBINED_MEME.exists(), \")\")\n",
    "print(\"[anchors]\", ANCHORS_PATH)\n",
    "\n",
    "# -------- helpers --------\n",
    "def norm_id(x):\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\",\"\", re.sub(r\"\\.(t?\\d+)$\",\"\", (str(x) or \"\").split()[0].split(\"|\")[-1]))\n",
    "\n",
    "def distinct_colors(n):\n",
    "    cols=[]\n",
    "    for i in range(max(1,n)):\n",
    "        h=i/max(1,n); s=0.60; l=0.55\n",
    "        def hue2rgb(p,q,t):\n",
    "            if t<0: t+=1\n",
    "            if t>1: t-=1\n",
    "            if t<1/6: return p+(q-p)*6*t\n",
    "            if t<1/2: return q\n",
    "            if t<2/3: return p+(q-p)*(2/3-t)*6\n",
    "            return p\n",
    "        q=l+s-l*s; p=2*l-q\n",
    "        r=hue2rgb(p,q,h+1/3); g=hue2rgb(p,q,h); b=hue2rgb(p,q,h-1/3)\n",
    "        cols.append('#%02x%02x%02x'% (int(r*255),int(g*255),int(b*255)))\n",
    "    return cols\n",
    "\n",
    "# -------- load tables --------\n",
    "hits = pd.read_csv(HITS_PATH, sep=\"\\t\")\n",
    "tt   = pd.read_csv(TOMTOM_TSV, sep=\"\\t\", comment=\"#\")\n",
    "anchors = pd.read_csv(ANCHORS_PATH, sep=\"\\t\")\n",
    "\n",
    "for c in (\"motif_alt_id\",\"sequence_name\"):\n",
    "    hits[c] = hits[c].astype(str).str.strip()\n",
    "for c in (\"Query_ID\",\"Target_ID\"):\n",
    "    tt[c] = tt[c].astype(str).str.strip()\n",
    "\n",
    "# -------- build MEME-# → CONSENSUS from combined MEME --------\n",
    "# Your file looks like: \"MOTIF <CONSENSUS>   MEME-#   width=...\"\n",
    "# So we must extract MEME-# from token3 and CONSENSUS from token2.\n",
    "def build_bridge_from_combined(path: Path):\n",
    "    memeid_to_cons = {}\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as fh:\n",
    "        for ln in fh:\n",
    "            if not ln.startswith(\"MOTIF \"): \n",
    "                continue\n",
    "            # split only first 3 tokens: MOTIF, <CONSENSUS>, <REST>\n",
    "            parts = ln.strip().split(maxsplit=2)\n",
    "            if len(parts) < 3: \n",
    "                continue\n",
    "            consensus = parts[1]               # e.g., GKRLSKVETLRSAIDYIRQLRQIL\n",
    "            rest     = parts[2]               # e.g., \"MEME-1\\twidth = 24 ...\"\n",
    "            m = re.search(r'(MEME-\\d+)', rest)\n",
    "            if m:\n",
    "                memeid_to_cons[m.group(1)] = consensus\n",
    "    return pd.DataFrame(\n",
    "        [(k,v) for k,v in memeid_to_cons.items()],\n",
    "        columns=[\"meme_id\",\"consensus\"]\n",
    "    )\n",
    "\n",
    "bridge = build_bridge_from_combined(COMBINED_MEME)\n",
    "if bridge.empty:\n",
    "    raise SystemExit(\"Failed to extract MEME-# → CONSENSUS from _combined_all_memes.txt. Check the file format.\")\n",
    "\n",
    "print(\"[bridge] MEME ids in hits:\", hits[\"motif_alt_id\"].nunique(),\n",
    "      \"  in bridge:\", bridge[\"meme_id\"].nunique(),\n",
    "      \"  overlap:\", len(set(hits[\"motif_alt_id\"]) & set(bridge[\"meme_id\"])))\n",
    "\n",
    "# Map hits to consensus\n",
    "hits = hits.merge(bridge, left_on=\"motif_alt_id\", right_on=\"meme_id\", how=\"left\")\n",
    "if hits[\"consensus\"].isna().any():\n",
    "    miss = hits[hits[\"consensus\"].isna()][\"motif_alt_id\"].unique()[:10]\n",
    "    print(\"WARNING: some MEME ids missing in bridge (showing up to 10):\", miss)\n",
    "\n",
    "# Per-PWM label if needed\n",
    "if {\"source_clade\",\"motif_id\"}.issubset(hits.columns):\n",
    "    hits[\"global_motif_id\"] = hits[\"source_clade\"].astype(str) + \"|\" + hits[\"motif_id\"].astype(str)\n",
    "else:\n",
    "    hits[\"global_motif_id\"] = hits[\"motif_alt_id\"].astype(str)\n",
    "\n",
    "# -------- cluster consensuses via strict Tomtom RBH (or disable) --------\n",
    "def build_clusters_strict(hits_df: pd.DataFrame, tt_df: pd.DataFrame):\n",
    "    # thresholds\n",
    "    if \"q-value\" in tt_df.columns:\n",
    "        ttf = tt_df[tt_df[\"q-value\"].fillna(1.0) <= Q_MAX].copy()\n",
    "    else:\n",
    "        ttf = tt_df[tt_df[\"p-value\"].fillna(1.0) <= P_MAX].copy()\n",
    "    if \"Overlap\" in ttf.columns:\n",
    "        ttf = ttf[ttf[\"Overlap\"].fillna(0) >= MIN_OVERLAP].copy()\n",
    "    # drop self\n",
    "    ttf = ttf[ttf[\"Query_ID\"] != ttf[\"Target_ID\"]].copy()\n",
    "    # RBH on p (fallback q)\n",
    "    if \"p-value\" in ttf.columns:\n",
    "        ttf[\"rank_q\"] = ttf.groupby(\"Query_ID\")[\"p-value\"].rank(method=\"first\")\n",
    "        ttf[\"rank_t\"] = ttf.groupby(\"Target_ID\")[\"p-value\"].rank(method=\"first\")\n",
    "    else:\n",
    "        ttf[\"rank_q\"] = ttf.groupby(\"Query_ID\")[\"q-value\"].rank(method=\"first\")\n",
    "        ttf[\"rank_t\"] = ttf.groupby(\"Target_ID\")[\"q-value\"].rank(method=\"first\")\n",
    "    rbh = ttf[(ttf[\"rank_q\"]==1) & (ttf[\"rank_t\"]==1)][[\"Query_ID\",\"Target_ID\"]]\n",
    "\n",
    "    # adjacency\n",
    "    adj = defaultdict(set)\n",
    "    for _, r in rbh.iterrows():\n",
    "        q, t = str(r[\"Query_ID\"]), str(r[\"Target_ID\"])\n",
    "        adj[q].add(t); adj[t].add(q)\n",
    "    # ensure isolated consensuses from hits are present\n",
    "    for cons in hits_df[\"consensus\"].dropna().astype(str).unique():\n",
    "        _ = adj[cons]\n",
    "\n",
    "    # BFS components\n",
    "    visited=set(); cons2cluster={}\n",
    "    cid=0\n",
    "    for node in list(adj.keys()):\n",
    "        if node in visited: continue\n",
    "        cid += 1\n",
    "        lab = f\"MTFCL_{cid:04d}\"\n",
    "        dq = deque([node]); visited.add(node); cons2cluster[node]=lab\n",
    "        while dq:\n",
    "            u=dq.popleft()\n",
    "            for v in adj[u]:\n",
    "                if v not in visited:\n",
    "                    visited.add(v); cons2cluster[v]=lab; dq.append(v)\n",
    "    return cons2cluster\n",
    "\n",
    "if CLUSTER_MODE == \"none\":\n",
    "    hits[\"plot_label\"] = hits[\"global_motif_id\"].astype(str)\n",
    "else:\n",
    "    cons2cluster = build_clusters_strict(hits, tt)\n",
    "    hits[\"plot_label\"] = hits[\"consensus\"].astype(str).map(cons2cluster)\n",
    "    # singletons (consensus without RBH partners)\n",
    "    mask_na = hits[\"plot_label\"].isna() & hits[\"consensus\"].notna()\n",
    "    hits.loc[mask_na, \"plot_label\"] = hits.loc[mask_na, \"consensus\"].apply(lambda s: f\"SINGLE::{s}\")\n",
    "\n",
    "print(\"Unique plot labels:\", hits[\"plot_label\"].nunique())\n",
    "\n",
    "# -------- robust anchors join --------\n",
    "for c in (\"start\",\"stop\"):\n",
    "    hits[c] = pd.to_numeric(hits[c], errors=\"coerce\")\n",
    "anchors[\"seq_norm_norm\"] = anchors[\"seq_id\"].map(norm_id)\n",
    "\n",
    "# 1) normed join\n",
    "hits[\"seq_norm\"] = hits[\"sequence_name\"].map(norm_id)\n",
    "joined = hits.merge(\n",
    "    anchors.rename(columns={\"seq_norm_norm\":\"seq_norm\"})[\n",
    "        [\"seq_norm\",\"ali_from\",\"ali_to\",\"anchor_pos\"]\n",
    "    ],\n",
    "    on=\"seq_norm\", how=\"left\"\n",
    ")\n",
    "\n",
    "# 2) raw id join if needed\n",
    "need = joined[\"anchor_pos\"].isna()\n",
    "if need.any():\n",
    "    j2 = hits.loc[need].merge(\n",
    "        anchors[[\"seq_id\",\"ali_from\",\"ali_to\",\"anchor_pos\"]],\n",
    "        left_on=\"sequence_name\", right_on=\"seq_id\", how=\"left\"\n",
    "    )\n",
    "    joined.loc[need, [\"ali_from\",\"ali_to\",\"anchor_pos\"]] = j2[[\"ali_from\",\"ali_to\",\"anchor_pos\"]].values\n",
    "\n",
    "# 3) try adding \".t1\"\n",
    "need = joined[\"anchor_pos\"].isna()\n",
    "if need.any():\n",
    "    tmp = hits.loc[need].copy()\n",
    "    tmp[\"sequence_name_t1\"] = tmp[\"sequence_name\"].astype(str) + \".t1\"\n",
    "    j3 = tmp.merge(\n",
    "        anchors.rename(columns={\"seq_id\":\"seq_id_raw\"})[[\"seq_id_raw\",\"ali_from\",\"ali_to\",\"anchor_pos\"]],\n",
    "        left_on=\"sequence_name_t1\", right_on=\"seq_id_raw\", how=\"left\"\n",
    "    )\n",
    "    idx = joined.index[need]\n",
    "    joined.loc[idx, [\"ali_from\",\"ali_to\",\"anchor_pos\"]] = j3[[\"ali_from\",\"ali_to\",\"anchor_pos\"]].values\n",
    "\n",
    "print(\"Anchors matched:\", joined[\"anchor_pos\"].notna().sum(), \"/\", len(joined))\n",
    "if joined[\"anchor_pos\"].notna().sum() == 0 and joined[\"ali_from\"].notna().any() and joined[\"ali_to\"].notna().any():\n",
    "    joined[\"anchor_pos\"] = (joined[\"ali_from\"] + joined[\"ali_to\"]) / 2.0\n",
    "    print(\"Using fallback anchor midpoint from ali span.\")\n",
    "\n",
    "# keep only rows with usable anchor\n",
    "joined = joined.dropna(subset=[\"anchor_pos\"]).copy()\n",
    "print(\"Rows with usable anchors:\", len(joined))\n",
    "\n",
    "# -------- relative coords + pick top-K non-overlapping per sequence --------\n",
    "for c in (\"start\",\"stop\",\"ali_from\",\"ali_to\",\"anchor_pos\"):\n",
    "    joined[c] = pd.to_numeric(joined[c], errors=\"coerce\")\n",
    "joined[\"rel_start\"] = joined[\"start\"] - joined[\"anchor_pos\"]\n",
    "joined[\"rel_end\"]   = joined[\"stop\"]  - joined[\"anchor_pos\"]\n",
    "\n",
    "if \"target_family\" not in joined.columns:\n",
    "    joined[\"target_family\"] = \"Unknown\"\n",
    "\n",
    "def pick_nonoverlapping(group):\n",
    "    group = group.sort_values(\"p-value\") if \"p-value\" in group.columns else group\n",
    "    chosen=[]; keep=[]\n",
    "    for _, r in group.iterrows():\n",
    "        s,e = float(r[\"start\"]), float(r[\"stop\"])\n",
    "        ok=True\n",
    "        for cs,ce in chosen:\n",
    "            if not (e < cs - NONOVERLAP_PAD or s > ce + NONOVERLAP_PAD):\n",
    "                ok=False; break\n",
    "        if ok:\n",
    "            chosen.append((s,e)); keep.append(r)\n",
    "        if len(keep) >= TOP_K: break\n",
    "    return pd.DataFrame(keep)\n",
    "\n",
    "picked = (joined.groupby(\"sequence_name\", group_keys=False)\n",
    "          .apply(pick_nonoverlapping)\n",
    "          .reset_index(drop=True))\n",
    "\n",
    "plotcols = [\"sequence_name\",\"plot_label\",\"rel_start\",\"rel_end\",\"start\",\"stop\",\n",
    "            \"ali_from\",\"ali_to\",\"anchor_pos\",\"target_family\",\"motif_id\",\"motif_alt_id\",\"consensus\",\"p-value\"]\n",
    "plotdf = picked[plotcols].copy()\n",
    "plot_path = REPORT / \"ASC_architecture.plotdata.tsv\"\n",
    "plotdf.to_csv(plot_path, sep=\"\\t\", index=False)\n",
    "print(\"Wrote plotdata:\", plot_path, \" rows:\", len(plotdf),\n",
    "      \" seqs:\", plotdf[\"sequence_name\"].nunique(), \" labels:\", plotdf[\"plot_label\"].nunique())\n",
    "\n",
    "# -------- plotting --------\n",
    "def plot_arch(df, title, outpng):\n",
    "    if df.empty:\n",
    "        print(f\"[Skip] {title}: no rows\"); return\n",
    "    labels = sorted(df[\"plot_label\"].astype(str).unique())\n",
    "    COLOR = dict(zip(labels, distinct_colors(len(labels))))\n",
    "\n",
    "    fam_map = (df.groupby(\"sequence_name\")[\"target_family\"]\n",
    "               .agg(lambda s: s.value_counts().idxmax() if s.notna().any() else \"Unknown\"))\n",
    "    def seq_key(s): return (fam_map.get(s,\"Unknown\"), s)\n",
    "    seqs = sorted(df[\"sequence_name\"].unique(), key=seq_key)\n",
    "\n",
    "    H = max(3.0, 0.18*len(seqs)); W = 12\n",
    "    fig, ax = plt.subplots(figsize=(W,H), dpi=200)\n",
    "    ymap = {s:i for i,s in enumerate(seqs)}\n",
    "\n",
    "    # PF00010 span and baseline\n",
    "    for s in seqs:\n",
    "        y = ymap[s]\n",
    "        sub = df[df[\"sequence_name\"]==s].iloc[0]\n",
    "        if pd.notna(sub.get(\"ali_from\", np.nan)) and pd.notna(sub.get(\"ali_to\", np.nan)) and pd.notna(sub.get(\"anchor_pos\", np.nan)):\n",
    "            ali_s = sub[\"ali_from\"] - sub[\"anchor_pos\"]\n",
    "            ali_e = sub[\"ali_to\"]   - sub[\"anchor_pos\"]\n",
    "        else:\n",
    "            ali_s, ali_e = -15, 15\n",
    "        ax.add_patch(plt.Rectangle((ali_s, y-0.35), max(4.0, ali_e-ali_s), 0.7,\n",
    "                                   color=\"#9e9e9e\", ec=\"#424242\", lw=0.5, zorder=2))\n",
    "        ax.plot([ali_s-200, ali_e+200], [y, y], color=\"#bdbdbd\", lw=1.0, zorder=1)\n",
    "\n",
    "    # motif rectangles\n",
    "    for _, r in df.iterrows():\n",
    "        y = ymap[r[\"sequence_name\"]]\n",
    "        x0, x1 = float(r[\"rel_start\"]), float(r[\"rel_end\"])\n",
    "        lab = str(r[\"plot_label\"])\n",
    "        ax.add_patch(plt.Rectangle((x0, y-0.25), max(6.0, x1-x0), 0.5,\n",
    "                                   color=COLOR[lab], ec=\"black\", lw=0.3, zorder=3))\n",
    "\n",
    "    all_x = np.concatenate([df[\"rel_start\"].values, df[\"rel_end\"].values])\n",
    "    finite = all_x[np.isfinite(all_x)]\n",
    "    q = np.quantile(np.abs(finite), 0.95) if finite.size else 200\n",
    "    ax.set_xlim(-max(200,q), max(200,q))\n",
    "    ax.set_ylim(-1, len(seqs)+0.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Position (aa) relative to bHLH anchor (0)\")\n",
    "    ax.set_yticks(range(len(seqs)))\n",
    "    ax.set_yticklabels(seqs, fontsize=6)\n",
    "    ax.axvline(0, color=\"#616161\", lw=1.0, ls=\"--\", zorder=1)\n",
    "\n",
    "    # legend (top 20 labels)\n",
    "    cov = df.groupby(\"plot_label\")[\"sequence_name\"].nunique().sort_values(ascending=False)\n",
    "    top = [str(k) for k in cov.head(20).index]\n",
    "    handles, labels = [], []\n",
    "    for lab in top:\n",
    "        patch = plt.Rectangle((0,0),1,1, color=COLOR[lab], ec=\"black\", lw=0.3)\n",
    "        handles.append(patch); labels.append(lab)\n",
    "    if handles:\n",
    "        ax.legend(handles, labels, title=(\"Clusters (strict RBH)\" if CLUSTER_MODE!=\"none\" else \"Motifs\"),\n",
    "                  bbox_to_anchor=(1.02,1), loc=\"upper left\", frameon=False, fontsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    outp = REPORT / outpng\n",
    "    fig.savefig(outp, bbox_inches=\"tight\", dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", outp)\n",
    "\n",
    "# Render\n",
    "plot_arch(plotdf, f\"ASC domain architecture (mode={CLUSTER_MODE}, top{TOP_K}/seq)\", \"ASC_domain_architecture.combined.png\")\n",
    "for fam in sorted(plotdf[\"target_family\"].dropna().unique()):\n",
    "    plot_arch(plotdf[plotdf[\"target_family\"]==fam], f\"ASC domain architecture — {fam} (mode={CLUSTER_MODE})\", f\"ASC_domain_architecture.{fam}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e25a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Using plotdata]  /Users/gorkemdurmaz/Desktop/asc_project_10/results/reports/ASC_architecture.plotdata.tsv\n",
      "[Using hits map] /Users/gorkemdurmaz/Desktop/asc_project_10/results/motifs/_summaries/NON_BHLH_SOFT.fimo_hits.filtered_perseq.tsv\n",
      "Wrote: /Users/gorkemdurmaz/Desktop/asc_project_10/results/reports/ASC_architecture.plotdata.with_family.tsv  rows: 134\n",
      "Legend: /Users/gorkemdurmaz/Desktop/asc_project_10/results/reports/ASC_architecture.plotlabel_to_domainlabel.tsv\n",
      "\n",
      "Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>plot_label</th>\n",
       "      <th>motif_id</th>\n",
       "      <th>motif_alt_id</th>\n",
       "      <th>family</th>\n",
       "      <th>clade</th>\n",
       "      <th>domain_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abru_g13702.t1</td>\n",
       "      <td>MTFCL_0007</td>\n",
       "      <td>GCDDNYNPYLPFYDDYGGAL</td>\n",
       "      <td>MEME-5</td>\n",
       "      <td>ASCc</td>\n",
       "      <td>ASCc</td>\n",
       "      <td>ASCc_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abru_g13702.t1</td>\n",
       "      <td>MTFCL_0004</td>\n",
       "      <td>MVQEMSQFSTH</td>\n",
       "      <td>MEME-8</td>\n",
       "      <td>ASCc</td>\n",
       "      <td>ASCc</td>\n",
       "      <td>ASCc_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abru_g13702.t1</td>\n",
       "      <td>MTFCL_0002</td>\n",
       "      <td>VNKENELHQRW</td>\n",
       "      <td>MEME-4</td>\n",
       "      <td>ASCc</td>\n",
       "      <td>ASCc</td>\n",
       "      <td>ASCc_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abru_g14616.t1</td>\n",
       "      <td>MTFCL_0005</td>\n",
       "      <td>PQGYRCDFGCPCNEG</td>\n",
       "      <td>MEME-3</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>ASCa_TrueSpiders_A</td>\n",
       "      <td>ASCa_ASCa_TrueSpiders_A_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abru_g14616.t1</td>\n",
       "      <td>MTFCL_0004</td>\n",
       "      <td>MEMFPHQDYPPQNS</td>\n",
       "      <td>MEME-8</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>ASCa_TrueSpiders_A</td>\n",
       "      <td>ASCa_ASCa_TrueSpiders_A_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abru_g14798.t1</td>\n",
       "      <td>MTFCL_0007</td>\n",
       "      <td>PSYCTTPSPVMMLMSESRSPPMFZ</td>\n",
       "      <td>MEME-5</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>ASCa_TrueSpiders_D</td>\n",
       "      <td>ASCa_ASCa_TrueSpiders_D_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abru_g14798.t1</td>\n",
       "      <td>MTFCL_0008</td>\n",
       "      <td>PPTHKLLLPLDRVGV</td>\n",
       "      <td>MEME-6</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>ASCa_TrueSpiders_D</td>\n",
       "      <td>ASCa_ASCa_TrueSpiders_D_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Abru_g14799.t1</td>\n",
       "      <td>MTFCL_0005</td>\n",
       "      <td>SGPAGGSGDLSPASSHPSDCSLV</td>\n",
       "      <td>MEME-3</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>ASCa_TrueSpiders_C</td>\n",
       "      <td>ASCa_ASCa_TrueSpiders_C_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Abru_g14799.t1</td>\n",
       "      <td>MTFCL_0002</td>\n",
       "      <td>QHTQDDQLMDIGLWFS</td>\n",
       "      <td>MEME-4</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>ASCa_related</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Abru_g14799.t1</td>\n",
       "      <td>MTFCL_0007</td>\n",
       "      <td>YGQDDCSSVASSEEI</td>\n",
       "      <td>MEME-5</td>\n",
       "      <td>ASCa</td>\n",
       "      <td>ASCa_TrueSpiders_C</td>\n",
       "      <td>ASCa_ASCa_TrueSpiders_C_related</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_name  plot_label                  motif_id motif_alt_id family  \\\n",
       "0  Abru_g13702.t1  MTFCL_0007      GCDDNYNPYLPFYDDYGGAL       MEME-5   ASCc   \n",
       "1  Abru_g13702.t1  MTFCL_0004               MVQEMSQFSTH       MEME-8   ASCc   \n",
       "2  Abru_g13702.t1  MTFCL_0002               VNKENELHQRW       MEME-4   ASCc   \n",
       "3  Abru_g14616.t1  MTFCL_0005           PQGYRCDFGCPCNEG       MEME-3   ASCa   \n",
       "4  Abru_g14616.t1  MTFCL_0004            MEMFPHQDYPPQNS       MEME-8   ASCa   \n",
       "5  Abru_g14798.t1  MTFCL_0007  PSYCTTPSPVMMLMSESRSPPMFZ       MEME-5   ASCa   \n",
       "6  Abru_g14798.t1  MTFCL_0008           PPTHKLLLPLDRVGV       MEME-6   ASCa   \n",
       "7  Abru_g14799.t1  MTFCL_0005   SGPAGGSGDLSPASSHPSDCSLV       MEME-3   ASCa   \n",
       "8  Abru_g14799.t1  MTFCL_0002          QHTQDDQLMDIGLWFS       MEME-4   ASCa   \n",
       "9  Abru_g14799.t1  MTFCL_0007           YGQDDCSSVASSEEI       MEME-5   ASCa   \n",
       "\n",
       "                clade                     domain_label  \n",
       "0                ASCc                     ASCc_related  \n",
       "1                ASCc                     ASCc_related  \n",
       "2                ASCc                     ASCc_related  \n",
       "3  ASCa_TrueSpiders_A  ASCa_ASCa_TrueSpiders_A_related  \n",
       "4  ASCa_TrueSpiders_A  ASCa_ASCa_TrueSpiders_A_related  \n",
       "5  ASCa_TrueSpiders_D  ASCa_ASCa_TrueSpiders_D_related  \n",
       "6  ASCa_TrueSpiders_D  ASCa_ASCa_TrueSpiders_D_related  \n",
       "7  ASCa_TrueSpiders_C  ASCa_ASCa_TrueSpiders_C_related  \n",
       "8                ASCa                     ASCa_related  \n",
       "9  ASCa_TrueSpiders_C  ASCa_ASCa_TrueSpiders_C_related  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Add interpretable 'family' and 'clade' labels to the plotting TSV ===\n",
    "# Maps from NON_BHLH_SOFT.fimo_hits.filtered_perseq.tsv (preferred) or fallback to ALL...\n",
    "# Key used: motif_key = f\"{motif_id}|{motif_alt_id}\"\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "PROJ = Path.cwd().resolve().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "OUT   = PROJ / \"results\"\n",
    "MOTIFS= OUT / \"motifs\"\n",
    "SUM   = MOTIFS / \"_summaries\"\n",
    "REPORT= OUT / \"reports\"\n",
    "\n",
    "PLOTDATA = REPORT / \"ASC_architecture.plotdata.tsv\"\n",
    "\n",
    "# Prefer NON_BHLH_SOFT; fall back if not present\n",
    "HITS_PATH = next((p for p in [\n",
    "    SUM / \"NON_BHLH_SOFT.fimo_hits.filtered_perseq.tsv\",\n",
    "    SUM / \"NON_BHLH.fimo_hits.filtered_perseq.tsv\",\n",
    "    SUM / \"ALL.fimo_hits.filtered_perseq.tsv\",\n",
    "] if p.exists()), None)\n",
    "\n",
    "if not PLOTDATA.exists():\n",
    "    raise SystemExit(f\"Missing plotdata: {PLOTDATA}\")\n",
    "if HITS_PATH is None or not HITS_PATH.exists():\n",
    "    raise SystemExit(\"Could not find a *_fimo_hits.filtered_perseq.tsv under _summaries/\")\n",
    "\n",
    "print(\"[Using plotdata] \", PLOTDATA)\n",
    "print(\"[Using hits map]\", HITS_PATH)\n",
    "\n",
    "# Load\n",
    "plotdf = pd.read_csv(PLOTDATA, sep=\"\\t\")\n",
    "hits   = pd.read_csv(HITS_PATH, sep=\"\\t\")\n",
    "\n",
    "# --- Build motif key in both frames (robust to missing columns) ---\n",
    "def make_key(df):\n",
    "    # use motif_id + motif_alt_id if both exist; else fall back to available\n",
    "    m_id  = df[\"motif_id\"].astype(str) if \"motif_id\" in df.columns else pd.Series([\"NA\"]*len(df))\n",
    "    m_alt = df[\"motif_alt_id\"].astype(str) if \"motif_alt_id\" in df.columns else (\n",
    "            df[\"consensus\"].astype(str) if \"consensus\" in df.columns else pd.Series([\"NA\"]*len(df)))\n",
    "    return m_id.str.strip() + \"|\" + m_alt.str.strip()\n",
    "\n",
    "plotdf[\"motif_key\"] = make_key(plotdf)\n",
    "hits[\"motif_key\"]   = make_key(hits)\n",
    "\n",
    "# --- Majority labels per motif (from hits) ---\n",
    "def majority(s, default=\"Unknown\"):\n",
    "    s = s.dropna()\n",
    "    return s.mode().iat[0] if len(s) else default\n",
    "\n",
    "fam_by_key   = hits.groupby(\"motif_key\")[\"target_family\"].apply(majority).rename(\"family\")\n",
    "clade_by_key = hits.groupby(\"motif_key\")[\"target_clade\"].apply(majority).rename(\"clade_raw\") if \"target_clade\" in hits.columns else pd.Series(dtype=object)\n",
    "\n",
    "labels = fam_by_key.to_frame().join(clade_by_key, how=\"left\")\n",
    "# Resolve clade: if Unassigned or missing, use family\n",
    "labels[\"clade\"] = labels.apply(lambda r: r[\"clade_raw\"] if pd.notna(r[\"clade_raw\"]) and r[\"clade_raw\"]!=\"Unassigned\" else r[\"family\"], axis=1)\n",
    "labels = labels.drop(columns=[\"clade_raw\"], errors=\"ignore\").reset_index()\n",
    "\n",
    "# --- Merge labels into plotdf ---\n",
    "plotdf_lbl = plotdf.merge(labels, on=\"motif_key\", how=\"left\")\n",
    "\n",
    "# Fallbacks if anything missing\n",
    "plotdf_lbl[\"family\"] = plotdf_lbl[\"family\"].fillna(\"Unknown\")\n",
    "plotdf_lbl[\"clade\"]  = plotdf_lbl[\"clade\"].fillna(plotdf_lbl[\"family\"])\n",
    "\n",
    "# Optional: human-friendly domain label to show in legends\n",
    "# e.g., \"ASCb_related\", \"ASCc_related\", or \"ASCa_<clade>_related\" if clade differs from family\n",
    "def make_domain_label(row):\n",
    "    fam = str(row[\"family\"])\n",
    "    cl  = str(row[\"clade\"])\n",
    "    if cl == fam or cl == \"Unknown\":\n",
    "        return f\"{fam}_related\"\n",
    "    else:\n",
    "        return f\"{fam}_{cl}_related\"\n",
    "plotdf_lbl[\"domain_label\"] = plotdf_lbl.apply(make_domain_label, axis=1)\n",
    "\n",
    "# Save augmented plot TSV\n",
    "OUT_TSV = REPORT / \"ASC_architecture.plotdata.with_family.tsv\"\n",
    "plotdf_lbl.to_csv(OUT_TSV, sep=\"\\t\", index=False)\n",
    "print(\"Wrote:\", OUT_TSV, \" rows:\", len(plotdf_lbl))\n",
    "\n",
    "# Also write a small legend mapping from plot_label → domain_label (and counts)\n",
    "legend = (plotdf_lbl.groupby([\"plot_label\",\"domain_label\"])\n",
    "          .agg(n_sites=(\"sequence_name\",\"count\"),\n",
    "               n_seqs=(\"sequence_name\",\"nunique\"))\n",
    "          .reset_index()\n",
    "          .sort_values([\"n_seqs\",\"n_sites\"], ascending=[False,False]))\n",
    "LEGEND_TSV = REPORT / \"ASC_architecture.plotlabel_to_domainlabel.tsv\"\n",
    "legend.to_csv(LEGEND_TSV, sep=\"\\t\", index=False)\n",
    "print(\"Legend:\", LEGEND_TSV)\n",
    "\n",
    "# Quick peek\n",
    "print(\"\\nPreview:\")\n",
    "display(plotdf_lbl[[\"sequence_name\",\"plot_label\",\"motif_id\",\"motif_alt_id\",\"family\",\"clade\",\"domain_label\"]].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f907bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 200 rows from FIMO file\n",
      "Columns: ['motif_id', 'motif_alt_id', 'sequence_name', 'start', 'stop', 'strand', 'score', 'p-value', 'q-value', 'matched_sequence', 'source_clade', 'seq_norm', 'target_clade', 'hit_mid', 'overlap_bHLH', 'is_bHLH_like', 'target_family', 'match_entropy', 'entropy_flag', 'families_hit', 'motif_col']\n",
      "Loaded anchor positions for 74 sequences\n",
      "Warning: 15 rows missing anchor_pos (will be excluded from plots)\n",
      "Using motif_col for family-aware motif labels\n",
      "Using families_hit column for family assignment\n",
      "Wrote mapping: /Users/gorkemdurmaz/Desktop/asc_project_10/results/reports/ASC_plotlabel_to_nicelabel_fimo.tsv (n clusters: 27)\n",
      "Saved: /Users/gorkemdurmaz/Desktop/asc_project_10/results/figures_new/ASC_domain_architecture_fimo.combined.png\n",
      "Saved: /Users/gorkemdurmaz/Desktop/asc_project_10/results/figures_new/ASC_domain_architecture_fimo.1.png\n",
      "Saved: /Users/gorkemdurmaz/Desktop/asc_project_10/results/figures_new/ASC_domain_architecture_fimo.2.png\n",
      "Saved: /Users/gorkemdurmaz/Desktop/asc_project_10/results/figures_new/ASC_domain_architecture_fimo.3.png\n",
      "\n",
      "=== Generating merged subclade plots ===\n",
      "Saved: /Users/gorkemdurmaz/Desktop/asc_project_10/results/figures_new/ASC_domain_architecture_fimo.ASCa_Chelicerate_merged.png\n",
      "Created: ASCa_Chelicerate_merged.png\n",
      "Saved: /Users/gorkemdurmaz/Desktop/asc_project_10/results/figures_new/ASC_domain_architecture_fimo.ASCa_ASCa3_merged.png\n",
      "Created: ASCa_ASCa3_merged.png\n",
      "\n",
      "=== Done! All plots generated. ===\n"
     ]
    }
   ],
   "source": [
    "# The LAST one and with FIMO no tomtom\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJ = Path.cwd().resolve().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "OUT = PROJ / \"results\"\n",
    "FIG = OUT / \"figures_new\"\n",
    "REPORT = OUT / \"reports\"\n",
    "REPORT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === Load FIMO hits data ===\n",
    "FIMO_FILE = PROJ / \"results/motifs/_summaries/NON_BHLH_SOFT.fimo_hits.filtered_perseq.tsv\"\n",
    "df = pd.read_csv(FIMO_FILE, sep=\"\\t\")\n",
    "\n",
    "print(f\"Loaded {len(df)} rows from FIMO file\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# === Load bHLH anchor positions from old dataset ===\n",
    "PLOT_WFAM_UPDATED = REPORT / \"ASC_architecture.plotdata.with_family.updated.tsv\"\n",
    "PLOT_WFAM = REPORT / \"ASC_architecture.plotdata.with_family.tsv\"\n",
    "PLOT_BASE = REPORT / \"ASC_architecture.plotdata.tsv\"\n",
    "\n",
    "if PLOT_WFAM_UPDATED.exists():\n",
    "    anchor_df = pd.read_csv(PLOT_WFAM_UPDATED, sep=\"\\t\")\n",
    "elif PLOT_WFAM.exists():\n",
    "    anchor_df = pd.read_csv(PLOT_WFAM, sep=\"\\t\")\n",
    "else:\n",
    "    anchor_df = pd.read_csv(PLOT_BASE, sep=\"\\t\")\n",
    "\n",
    "# Extract unique anchor positions per sequence\n",
    "anchor_info = anchor_df[[\"sequence_name\", \"anchor_pos\", \"ali_from\", \"ali_to\"]].drop_duplicates(\"sequence_name\")\n",
    "print(f\"Loaded anchor positions for {len(anchor_info)} sequences\")\n",
    "\n",
    "# Merge anchor info with FIMO data\n",
    "df = df.merge(anchor_info, on=\"sequence_name\", how=\"left\")\n",
    "\n",
    "# === Calculate relative positions using anchor_pos ===\n",
    "df[\"rel_start\"] = df[\"start\"] - df[\"anchor_pos\"]\n",
    "df[\"rel_end\"] = df[\"stop\"] - df[\"anchor_pos\"]\n",
    "\n",
    "# Check for sequences without anchor info\n",
    "missing_anchor = df[\"anchor_pos\"].isna().sum()\n",
    "if missing_anchor > 0:\n",
    "    print(f\"Warning: {missing_anchor} rows missing anchor_pos (will be excluded from plots)\")\n",
    "    df = df[df[\"anchor_pos\"].notna()].copy()\n",
    "\n",
    "# === Use motif_col as plot_label (includes family/clade + motif identity) ===\n",
    "if \"motif_col\" in df.columns:\n",
    "    df[\"plot_label\"] = df[\"motif_col\"].astype(str)\n",
    "    print(\"Using motif_col for family-aware motif labels\")\n",
    "else:\n",
    "    # Fallback to old method if motif_col doesn't exist\n",
    "    df[\"plot_label\"] = df[\"motif_id\"].astype(str) + \"|\" + df[\"motif_alt_id\"].astype(str)\n",
    "    print(\"Warning: motif_col not found, using motif_id|motif_alt_id instead\")\n",
    "\n",
    "# === Extract family and clade information ===\n",
    "# Use families_hit instead of target_family to avoid unassigned proteins\n",
    "if \"families_hit\" in df.columns:\n",
    "    df[\"family_for_plot\"] = df[\"families_hit\"].astype(str)\n",
    "    print(\"Using families_hit column for family assignment\")\n",
    "elif \"target_family\" in df.columns:\n",
    "    df[\"family_for_plot\"] = df[\"target_family\"].astype(str)\n",
    "    print(\"Warning: families_hit not found, using target_family instead\")\n",
    "else:\n",
    "    df[\"family_for_plot\"] = \"Unknown\"\n",
    "\n",
    "if \"target_clade\" not in df.columns:\n",
    "    df[\"target_clade\"] = \"Unknown\"\n",
    "\n",
    "# === Build consensus sequence (use matched_sequence) ===\n",
    "if \"matched_sequence\" not in df.columns:\n",
    "    df[\"consensus\"] = df[\"motif_id\"]\n",
    "else:\n",
    "    df[\"consensus\"] = df[\"matched_sequence\"]\n",
    "\n",
    "# === Helpers ===\n",
    "AA = set(list(\"ACDEFGHIKLMNPQRSTVWY\"))\n",
    "\n",
    "def short_consensus(s, k=6):\n",
    "    s = str(s or \"\")\n",
    "    s2 = \"\".join(ch for ch in s if ch in AA)\n",
    "    return s2[:k] if s2 else s[:k]\n",
    "\n",
    "def distinct_colors(n):\n",
    "    cols = []\n",
    "    for i in range(max(1, n)):\n",
    "        h = i / max(1, n)\n",
    "        s = 0.60\n",
    "        l = 0.55\n",
    "        def hue2rgb(p, q, t):\n",
    "            if t < 0: t += 1\n",
    "            if t > 1: t -= 1\n",
    "            if t < 1/6: return p + (q - p) * 6 * t\n",
    "            if t < 1/2: return q\n",
    "            if t < 2/3: return p + (q - p) * (2/3 - t) * 6\n",
    "            return p\n",
    "        q = l + s - l * s\n",
    "        p = 2 * l - q\n",
    "        r = hue2rgb(p, q, h + 1/3)\n",
    "        g = hue2rgb(p, q, h)\n",
    "        b = hue2rgb(p, q, h - 1/3)\n",
    "        cols.append('#%02x%02x%02x' % (int(r*255), int(g*255), int(b*255)))\n",
    "    return cols\n",
    "\n",
    "def majority_safe(s):\n",
    "    s = s.dropna()\n",
    "    s = s[s != \"Unknown\"]\n",
    "    if s.empty:\n",
    "        return \"Unknown\"\n",
    "    m = s.mode()\n",
    "    return m.iloc[0] if len(m) == 1 else \"Ambiguous\"\n",
    "\n",
    "# === Position & width features ===\n",
    "df[\"site_mid\"] = (df[\"rel_start\"] + df[\"rel_end\"]) / 2.0\n",
    "df[\"site_width\"] = (df[\"stop\"] - df[\"start\"] + 1).clip(lower=1)\n",
    "\n",
    "# === One-vote-per-sequence deduplication ===\n",
    "dedup = df.drop_duplicates([\"plot_label\", \"sequence_name\"])\n",
    "\n",
    "# === Build label table ===\n",
    "pos_w = (dedup.groupby(\"plot_label\")\n",
    "         .agg(med_pos=(\"site_mid\", \"median\"),\n",
    "              med_w=(\"site_width\", \"median\"),\n",
    "              n_seqs=(\"sequence_name\", \"nunique\"))\n",
    "         .reset_index())\n",
    "\n",
    "rep_cons = (df.groupby(\"plot_label\")[\"consensus\"]\n",
    "            .apply(majority_safe)\n",
    "            .rename(\"rep_consensus\"))\n",
    "\n",
    "dom_fam = (dedup.groupby(\"plot_label\")[\"family_for_plot\"]\n",
    "           .apply(majority_safe)\n",
    "           .rename(\"dominant_family\"))\n",
    "\n",
    "dom_cla = (dedup.groupby(\"plot_label\")[\"target_clade\"]\n",
    "           .apply(majority_safe)\n",
    "           .rename(\"dominant_clade\"))\n",
    "\n",
    "label_tbl = (pos_w.merge(rep_cons.reset_index(), on=\"plot_label\", how=\"left\")\n",
    "             .merge(dom_fam.reset_index(), on=\"plot_label\", how=\"left\")\n",
    "             .merge(dom_cla.reset_index(), on=\"plot_label\", how=\"left\"))\n",
    "\n",
    "# === Position bin ===\n",
    "def pos_bin(x):\n",
    "    if pd.isna(x): return \"posNA\"\n",
    "    if x < -150: return \"N-dist\"\n",
    "    if x < -50: return \"N-prox\"\n",
    "    if x <= 50: return \"bHLH-prox\"\n",
    "    if x <= 150: return \"C-prox\"\n",
    "    return \"C-dist\"\n",
    "\n",
    "label_tbl[\"pos_bin\"] = label_tbl[\"med_pos\"].apply(pos_bin)\n",
    "label_tbl[\"rep6\"] = label_tbl[\"rep_consensus\"].apply(short_consensus)\n",
    "label_tbl[\"med_w\"] = label_tbl[\"med_w\"].round(0).astype(\"Int64\")\n",
    "\n",
    "# Fill NaN for display\n",
    "if \"dominant_family\" not in label_tbl.columns:\n",
    "    label_tbl[\"dominant_family\"] = \"Unknown\"\n",
    "if \"dominant_clade\" not in label_tbl.columns:\n",
    "    label_tbl[\"dominant_clade\"] = \"Unknown\"\n",
    "\n",
    "label_tbl[\"clade_display\"] = label_tbl[\"dominant_clade\"].fillna(label_tbl[\"dominant_family\"])\n",
    "\n",
    "# === Build nice labels with clade info and motif sequence ===\n",
    "def extract_family_clade(motif_col_str):\n",
    "    \"\"\"Extract family and clade from motif_col like 'ASCa_TrueSpiders_A|MOTIF'\"\"\"\n",
    "    parts = str(motif_col_str).split(\"|\")[0].split(\"_\")\n",
    "    family = parts[0] if parts else \"Unknown\"\n",
    "    clade = \"_\".join(parts[1:]) if len(parts) > 1 else None\n",
    "    return family, clade\n",
    "\n",
    "label_tbl[\"motif_col_family\"], label_tbl[\"motif_col_clade\"] = zip(*label_tbl[\"plot_label\"].apply(extract_family_clade))\n",
    "\n",
    "# Get first 6 AA from motif_id for each plot_label\n",
    "motif_id_map = df.groupby(\"plot_label\")[\"motif_id\"].first().to_dict()\n",
    "label_tbl[\"motif_seq\"] = label_tbl[\"plot_label\"].map(motif_id_map).apply(short_consensus)\n",
    "\n",
    "# Build nice label with clade if specific, otherwise just family\n",
    "def build_nice_label(row):\n",
    "    family = row[\"motif_col_family\"]\n",
    "    clade = row[\"motif_col_clade\"]\n",
    "    motif_seq = row[\"motif_seq\"]\n",
    "    med_w = row[\"med_w\"]\n",
    "    pos_bin = row[\"pos_bin\"]\n",
    "    \n",
    "    # Include clade if it's clade-specific (not just family name)\n",
    "    if clade and clade not in [\"\", \"Unknown\"]:\n",
    "        prefix = f\"{family}_{clade}\"\n",
    "    else:\n",
    "        prefix = family\n",
    "    \n",
    "    return f\"{prefix} • {motif_seq} (w{med_w}, {pos_bin})\"\n",
    "\n",
    "label_tbl[\"nice_label\"] = label_tbl.apply(build_nice_label, axis=1)\n",
    "\n",
    "# Site counts\n",
    "site_counts = (df.groupby(\"plot_label\")[\"sequence_name\"]\n",
    "               .size()\n",
    "               .rename(\"n_sites\")\n",
    "               .reset_index())\n",
    "\n",
    "label_tbl = label_tbl.merge(site_counts, on=\"plot_label\", how=\"left\")\n",
    "label_tbl[\"n_sites\"] = label_tbl[\"n_sites\"].fillna(0).astype(\"Int64\")\n",
    "\n",
    "# === Save mapping ===\n",
    "MAP_TSV = REPORT / \"ASC_plotlabel_to_nicelabel_fimo.tsv\"\n",
    "label_tbl[[\"plot_label\", \"nice_label\", \"rep_consensus\", \"med_w\", \"med_pos\",\n",
    "           \"pos_bin\", \"dominant_family\", \"dominant_clade\", \"n_seqs\", \"n_sites\"]].to_csv(\n",
    "    MAP_TSV, sep=\"\\t\", index=False)\n",
    "print(f\"Wrote mapping: {MAP_TSV} (n clusters: {len(label_tbl)})\")\n",
    "\n",
    "# === Family color palette ===\n",
    "FAM_COLOR = {\n",
    "    \"ASCa\": \"#2e7d32\",     # green\n",
    "    \"ASCb\": \"#1565c0\",     # blue\n",
    "    \"ASCc\": \"#c62828\",     # red\n",
    "    \"ASH\": \"#ef6c00\",      # orange\n",
    "    \"Ase\": \"#00897b\",      # teal\n",
    "    \"ase\": \"#00897b\",      # teal\n",
    "    \"Unassigned\": \"#9e9e9e\",\n",
    "    \"Unknown\": \"#9e9e9e\",\n",
    "    \"1\": \"#2e7d32\",        # families_hit=1 often ASCa\n",
    "    \"2\": \"#1565c0\",        # families_hit=2 often ASCb\n",
    "    \"3\": \"#c62828\",        # families_hit=3 often ASCc\n",
    "}\n",
    "\n",
    "def family_color(f):\n",
    "    \"\"\"Get color for a family, checking multiple possible values\"\"\"\n",
    "    f_str = str(f)\n",
    "    # First check exact match\n",
    "    if f_str in FAM_COLOR:\n",
    "        return FAM_COLOR[f_str]\n",
    "    # Check if it starts with a known family name\n",
    "    for fam_key in [\"ASCa\", \"ASCb\", \"ASCc\", \"ASH\", \"ase\", \"Ase\"]:\n",
    "        if f_str.startswith(fam_key):\n",
    "            return FAM_COLOR[fam_key]\n",
    "    return FAM_COLOR[\"Unknown\"]\n",
    "\n",
    "def compute_x_extent(df_in):\n",
    "    \"\"\"Return symmetric x-limits based on farthest observed motif position\"\"\"\n",
    "    if {\"rel_start\", \"rel_end\"}.issubset(df_in.columns):\n",
    "        all_x = np.concatenate([df_in[\"rel_start\"].values, df_in[\"rel_end\"].values])\n",
    "        finite = all_x[np.isfinite(all_x)]\n",
    "    else:\n",
    "        finite = np.array([])\n",
    "    if finite.size:\n",
    "        max_abs = float(np.nanmax(np.abs(finite)))\n",
    "    else:\n",
    "        max_abs = 200.0\n",
    "    pad = max(50.0, 0.05 * max_abs)\n",
    "    lim = max_abs + pad\n",
    "    return -lim, lim\n",
    "\n",
    "# === Plotter ===\n",
    "def plot_arch_with_nice_legend(df_in, title, outpng, color_by=\"plot_label\"):\n",
    "    if df_in.empty:\n",
    "        print(f\"[Skip] {title}: no rows\")\n",
    "        return\n",
    "\n",
    "    # Color key for motif rectangles\n",
    "    if color_by == \"plot_label\":\n",
    "        labels = sorted(df_in[\"plot_label\"].astype(str).unique())\n",
    "        COLOR = dict(zip(labels, distinct_colors(len(labels))))\n",
    "        legend_items = labels\n",
    "        legend_label_map = dict(zip(label_tbl[\"plot_label\"].astype(str),\n",
    "                                   label_tbl[\"nice_label\"].astype(str)))\n",
    "        def label_to_color(row): return COLOR.get(str(row[\"plot_label\"]), \"#cccccc\")\n",
    "        def label_to_legend_text(k): return legend_label_map.get(k, k)\n",
    "        legend_title = \"Motif clusters\"\n",
    "    elif color_by == \"target_clade\":\n",
    "        clades = sorted(df_in[\"target_clade\"].astype(str).fillna(\"Unassigned\").unique())\n",
    "        COLOR = dict(zip(clades, distinct_colors(len(clades))))\n",
    "        legend_items = clades\n",
    "        def label_to_color(row): return COLOR.get(str(row.get(\"target_clade\", \"Unassigned\")), \"#cccccc\")\n",
    "        def label_to_legend_text(k): return k\n",
    "        legend_title = \"Subclades\"\n",
    "    else:\n",
    "        labels = sorted(df_in[\"plot_label\"].astype(str).unique())\n",
    "        COLOR = dict(zip(labels, distinct_colors(len(labels))))\n",
    "        legend_items = labels\n",
    "        legend_label_map = dict(zip(label_tbl[\"plot_label\"].astype(str),\n",
    "                                   label_tbl[\"nice_label\"].astype(str)))\n",
    "        def label_to_color(row): return COLOR.get(str(row[\"plot_label\"]), \"#cccccc\")\n",
    "        def label_to_legend_text(k): return legend_label_map.get(k, k)\n",
    "        legend_title = \"Motif clusters\"\n",
    "\n",
    "    # Per-sequence family - use source_clade and map to ASCa/ASCb/ASCc\n",
    "    # ASCb → ASCb, ASCc → ASCc, everything else (ASH, ase, ASCa_*) → ASCa\n",
    "    if \"source_clade\" in df_in.columns:\n",
    "        def map_to_family(clade):\n",
    "            clade_str = str(clade)\n",
    "            if clade_str == \"ASCb\":\n",
    "                return \"ASCb\"\n",
    "            elif clade_str == \"ASCc\":\n",
    "                return \"ASCc\"\n",
    "            else:\n",
    "                return \"ASCa\"  # ASH, ase, ASCa_TrueSpiders_*, etc.\n",
    "        \n",
    "        fam_map = df_in.groupby(\"sequence_name\")[\"source_clade\"].first().apply(map_to_family).to_dict()\n",
    "    else:\n",
    "        # Fallback\n",
    "        fam_map = {}\n",
    "    \n",
    "    def seq_key(s): return (fam_map.get(s, \"ASCa\"), s)\n",
    "\n",
    "    seqs = sorted(df_in[\"sequence_name\"].unique(), key=seq_key)\n",
    "\n",
    "    # Dynamic x-range\n",
    "    x_left, x_right = compute_x_extent(df_in)\n",
    "\n",
    "    H = max(3.0, 0.18 * len(seqs))\n",
    "    W = 12\n",
    "    fig, ax = plt.subplots(figsize=(W, H), dpi=200)\n",
    "    ymap = {s: i for i, s in enumerate(seqs)}\n",
    "\n",
    "    # Draw baselines and bHLH boxes with true lengths\n",
    "    for s in seqs:\n",
    "        y = ymap[s]\n",
    "        # Simple baseline\n",
    "        ax.plot([x_left, x_right], [y, y], color=\"#bdbdbd\", lw=1.0, zorder=1)\n",
    "        \n",
    "        # Get actual bHLH span for this sequence from anchor_df\n",
    "        seq_anchor = df_in[df_in[\"sequence_name\"] == s].iloc[0]\n",
    "        if pd.notna(seq_anchor.get(\"ali_from\")) and pd.notna(seq_anchor.get(\"ali_to\")) and pd.notna(seq_anchor.get(\"anchor_pos\")):\n",
    "            ali_s = seq_anchor[\"ali_from\"] - seq_anchor[\"anchor_pos\"]\n",
    "            ali_e = seq_anchor[\"ali_to\"] - seq_anchor[\"anchor_pos\"]\n",
    "            bhlh_width = ali_e - ali_s\n",
    "        else:\n",
    "            # Fallback to default\n",
    "            ali_s, ali_e = -15, 15\n",
    "            bhlh_width = 30\n",
    "        \n",
    "        # bHLH box with true width\n",
    "        ax.add_patch(plt.Rectangle((ali_s, y - 0.35), bhlh_width, 0.7,\n",
    "                                   color=\"#9e9e9e\", ec=\"#424242\", lw=0.5, zorder=2))\n",
    "\n",
    "    # Draw motif rectangles with true widths and transparency\n",
    "    for _, r in df_in.iterrows():\n",
    "        y = ymap[r[\"sequence_name\"]]\n",
    "        x0, x1 = float(r.get(\"rel_start\", np.nan)), float(r.get(\"rel_end\", np.nan))\n",
    "        if np.isnan(x0) or np.isnan(x1):\n",
    "            continue\n",
    "        # Use actual width (no minimum)\n",
    "        motif_width = x1 - x0\n",
    "        ax.add_patch(plt.Rectangle((x0, y - 0.25), motif_width, 0.5,\n",
    "                                   color=label_to_color(r), ec=\"black\", lw=0.3, \n",
    "                                   alpha=0.7, zorder=3))  # alpha=0.7 for transparency\n",
    "\n",
    "    # Axis setup\n",
    "    ax.set_xlim(x_left, x_right)\n",
    "    ax.set_ylim(-1, len(seqs) + 0.5)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Position (aa) relative to reference\")\n",
    "    ax.axvline(0, color=\"#616161\", lw=1.0, ls=\"--\", zorder=1)\n",
    "\n",
    "    # Colored y-axis labels by family\n",
    "    ytick_positions = range(len(seqs))\n",
    "    ytick_labels = []\n",
    "    ytick_colors = []\n",
    "    for s in seqs:\n",
    "        fam = fam_map.get(s, \"Unknown\")\n",
    "        color = family_color(fam)\n",
    "        ytick_labels.append(s)\n",
    "        ytick_colors.append(color)\n",
    "    ax.set_yticks(ytick_positions)\n",
    "    for ticklabel, color in zip(ax.set_yticklabels(ytick_labels, fontsize=6), ytick_colors):\n",
    "        ticklabel.set_color(color)\n",
    "\n",
    "    # Legend\n",
    "    if color_by == \"plot_label\":\n",
    "        cov = df_in.groupby(\"plot_label\")[\"sequence_name\"].nunique().sort_values(ascending=False)\n",
    "        show_keys = [str(k) for k in cov.head(20).index]\n",
    "    else:\n",
    "        show_keys = legend_items\n",
    "\n",
    "    handles, leg_labels = [], []\n",
    "    for k in show_keys:\n",
    "        patch = plt.Rectangle((0, 0), 1, 1, color=COLOR.get(k, \"#cccccc\"), ec=\"black\", lw=0.3)\n",
    "        handles.append(patch)\n",
    "        leg_labels.append(label_to_legend_text(k))\n",
    "    if handles:\n",
    "        ax.legend(handles, leg_labels, title=legend_title,\n",
    "                  bbox_to_anchor=(1.02, 1), loc=\"upper left\", frameon=False, fontsize=7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    outp = FIG / outpng\n",
    "    fig.savefig(outp, bbox_inches=\"tight\", dpi=200)\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved: {outp}\")\n",
    "\n",
    "# === Generate plots ===\n",
    "FIG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Combined plot\n",
    "plot_arch_with_nice_legend(df, \"ASC domain architecture (FIMO-based)\",\n",
    "                          \"ASC_domain_architecture_fimo.combined.png\")\n",
    "\n",
    "# 2) Per-family plots\n",
    "if \"family_for_plot\" in df.columns:\n",
    "    for fam in sorted(df[\"family_for_plot\"].dropna().unique()):\n",
    "        if fam == \"Unknown\":\n",
    "            continue\n",
    "        sub = df[df[\"family_for_plot\"] == fam]\n",
    "        plot_arch_with_nice_legend(sub, f\"ASC domain architecture — {fam}\",\n",
    "                                  f\"ASC_domain_architecture_fimo.{fam}.png\")\n",
    "\n",
    "        # 3) ASCa extras: per-subclade + clade-colored overview\n",
    "        if str(fam) == \"ASCa\" and \"target_clade\" in sub.columns:\n",
    "            clades = [c for c in sorted(sub[\"target_clade\"].dropna().unique())\n",
    "                     if c != \"Unassigned\"]\n",
    "            for cl in clades:\n",
    "                subc = sub[sub[\"target_clade\"] == cl]\n",
    "                safe_cl = re.sub('[^A-Za-z0-9_.-]+', '_', str(cl))\n",
    "                plot_arch_with_nice_legend(subc,\n",
    "                                          f\"ASC domain architecture — ASCa • subclade {cl}\",\n",
    "                                          f\"ASC_domain_architecture_fimo.ASCa_subclade_{safe_cl}.png\")\n",
    "            \n",
    "            # Clade-colored overview\n",
    "            plot_arch_with_nice_legend(sub,\n",
    "                                      \"ASC domain architecture — ASCa (colored by subclade)\",\n",
    "                                      \"ASC_domain_architecture_fimo.ASCa_by_subclade.png\",\n",
    "                                      color_by=\"target_clade\")\n",
    "\n",
    "# === Extra ASCa plots with merged subclades ===\n",
    "print(\"\\n=== Generating merged subclade plots ===\")\n",
    "\n",
    "# Safety: require these columns\n",
    "need_cols = {\"target_clade\", \"sequence_name\", \"rel_start\", \"rel_end\", \"plot_label\"}\n",
    "missing = need_cols - set(df.columns)\n",
    "if missing:\n",
    "    print(f\"[Skip] Missing columns for merged plots: {missing}\")\n",
    "else:\n",
    "    # Mapping: merge selected subclades into new combined labels\n",
    "    MERGE_MAP = {\n",
    "        \"ASCa_TrueSpiders_C\": \"Chelicerate ASCa\",\n",
    "        \"ASCa_TrueSpiders_D\": \"Chelicerate ASCa\",\n",
    "        \"ASCa_TrueSpiders_E\": \"ASCa3\",\n",
    "        \"ASCa_TrueSpiders_F\": \"ASCa3\",\n",
    "    }\n",
    "\n",
    "    # Filter to ASCa using source_clade (which includes all ASCa subclades, ASH, ase)\n",
    "    df_asca = df[df[\"source_clade\"].str.startswith(\"ASCa\", na=False) | \n",
    "                  df[\"source_clade\"].isin([\"ASH\", \"ase\"])].copy()\n",
    "    \n",
    "    if df_asca.empty:\n",
    "        print(\"[Skip] No ASCa rows found.\")\n",
    "    else:\n",
    "        # Create a merged clade column (default to original)\n",
    "        df_asca[\"target_clade_merged\"] = df_asca[\"target_clade\"].astype(str).apply(\n",
    "            lambda x: MERGE_MAP.get(x, x)\n",
    "        )\n",
    "\n",
    "        # ---------- Plot 1: Chelicerate ASCa (C + D merged) ----------\n",
    "        chelic_keep = {\"ASCa_TrueSpiders_C\", \"ASCa_TrueSpiders_D\"}\n",
    "        sub_chelic = df_asca[df_asca[\"target_clade\"].isin(chelic_keep)].copy()\n",
    "        if sub_chelic.empty:\n",
    "            print(\"[Skip] No rows for Chelicerate ASCa (C/D).\")\n",
    "        else:\n",
    "            # Swap in merged label as the plotting clade\n",
    "            sub_chelic[\"target_clade\"] = sub_chelic[\"target_clade_merged\"]\n",
    "            plot_arch_with_nice_legend(\n",
    "                sub_chelic,\n",
    "                \"ASC domain architecture — ASCa (Chelicerate ASCa: C+D merged)\",\n",
    "                \"ASC_domain_architecture_fimo.ASCa_Chelicerate_merged.png\",\n",
    "                color_by=\"plot_label\"  # motifs colored by motif cluster\n",
    "            )\n",
    "            print(\"Created: ASCa_Chelicerate_merged.png\")\n",
    "\n",
    "        # ---------- Plot 2: ASCa3 (E + F merged) ----------\n",
    "        asca3_keep = {\"ASCa_TrueSpiders_E\", \"ASCa_TrueSpiders_F\"}\n",
    "        sub_asca3 = df_asca[df_asca[\"target_clade\"].isin(asca3_keep)].copy()\n",
    "        if sub_asca3.empty:\n",
    "            print(\"[Skip] No rows for ASCa3 (E/F).\")\n",
    "        else:\n",
    "            sub_asca3[\"target_clade\"] = sub_asca3[\"target_clade_merged\"]\n",
    "            plot_arch_with_nice_legend(\n",
    "                sub_asca3,\n",
    "                \"ASC domain architecture — ASCa (ASCa3: E+F merged)\",\n",
    "                \"ASC_domain_architecture_fimo.ASCa_ASCa3_merged.png\",\n",
    "                color_by=\"plot_label\"  # motifs colored by motif cluster\n",
    "            )\n",
    "            print(\"Created: ASCa_ASCa3_merged.png\")\n",
    "\n",
    "print(\"\\n=== Done! All plots generated. ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
