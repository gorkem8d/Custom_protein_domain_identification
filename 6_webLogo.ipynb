{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7180fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 0) Setup & configuration\n",
    "# =========================\n",
    "from pathlib import Path\n",
    "import subprocess, sys, re, textwrap, os\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "# ---- INPUTS  ----\n",
    "FIMO_PERSEQ = Path(\"results/motifs/_summaries/ALL.fimo_hits.filtered_perseq.tsv\")\n",
    "TARGET_FASTA = Path(\"data/ASC_targets.fasta\")   # all target proteins used in FIMO\n",
    "# bHLH coordinates table: one row per protein with columns: id, start, end (1-based, inclusive)\n",
    "# If you don't have this exact file, point to your HMMER domtblout-derived table (same columns)\n",
    "BHLH_COORDS  = Path(\"results/bHLH_anchors.tsv\")\n",
    "\n",
    "# Optional mapping file: two columns [id, clade] where clade in {\"insect\",\"spider\"}\n",
    "# If not provided, a regex-based classifier below will try to infer from IDs.\n",
    "TAXON_MAP = Path(\"data/id_to_clade.tsv\")  # set to None if you don't have it\n",
    "if not TAXON_MAP.exists():\n",
    "    TAXON_MAP = None\n",
    "\n",
    "# ---- OUTPUTS ----\n",
    "OUTDIR = Path(\"results/weblogos_bHLH_by_lineage\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# MAFFT required for alignment-based logos \n",
    "MAFFT = \"mafft\"   # ensure it's on PATH (eg, conda install mafft)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7d8f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(91,\n",
       " ['Abru_g13702.t1',\n",
       "  'Abru_g14616.t1',\n",
       "  'Abru_g14798.t1',\n",
       "  'Abru_g14799.t1',\n",
       "  'Abru_g14800.t1'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 1) Load FIMO per-seq list\n",
    "\n",
    "# Expecting a column that holds sequence/protein IDs. Common names: 'sequence_name', 'seq_id', or 'target'\n",
    "# We will try a few and fail helpfully if none present.\n",
    "fimo = pd.read_csv(FIMO_PERSEQ, sep=\"\\t\")\n",
    "cand_cols = [c for c in fimo.columns if c.lower() in {\"sequence_name\", \"seq_name\", \"target\", \"seq_id\", \"sequence\"}]\n",
    "if not cand_cols:\n",
    "    raise ValueError(f\"Couldn't find an ID column in {FIMO_PERSEQ}. Columns: {list(fimo.columns)}\")\n",
    "id_col = cand_cols[0]\n",
    "ids_from_fimo = set(fimo[id_col].astype(str).unique())\n",
    "len(ids_from_fimo), list(sorted(list(ids_from_fimo))[:5])[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2a7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bHLH coord rows kept: 89\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abru_g13702.t1</td>\n",
       "      <td>117</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abru_g14616.t1</td>\n",
       "      <td>58</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abru_g14798.t1</td>\n",
       "      <td>82</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abru_g14799.t1</td>\n",
       "      <td>91</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abru_g14800.t1</td>\n",
       "      <td>110</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  start  end\n",
       "0  Abru_g13702.t1    117  168\n",
       "1  Abru_g14616.t1     58  110\n",
       "2  Abru_g14798.t1     82  152\n",
       "3  Abru_g14799.t1     91  143\n",
       "4  Abru_g14800.t1    110  162"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2) Load bHLH coords & restrict to IDs\n",
    "\n",
    "coords = pd.read_csv(BHLH_COORDS, sep=\"\\t\")\n",
    "\n",
    "# helper to pick the first existing column from a preference list\n",
    "def pick_col(df_cols_lower_to_orig, *candidates):\n",
    "    for c in candidates:\n",
    "        if c in df_cols_lower_to_orig:\n",
    "            return df_cols_lower_to_orig[c]\n",
    "    return None\n",
    "\n",
    "# map lowercase -> original\n",
    "lower2orig = {c.lower(): c for c in coords.columns}\n",
    "\n",
    "col_id = pick_col(lower2orig, \"id\", \"seq_id\", \"protein\", \"name\")\n",
    "if col_id is None:\n",
    "    raise ValueError(f\"No ID column found in {BHLH_COORDS}. Have: {list(coords.columns)}\")\n",
    "\n",
    "# prefer env_* (domain envelope) then ali_* (aligned core) then generic start/end\n",
    "col_start = pick_col(lower2orig, \"env_from\", \"ali_from\", \"start\", \"query_start\")\n",
    "col_end   = pick_col(lower2orig, \"env_to\",   \"ali_to\",   \"end\",   \"query_end\")\n",
    "if col_start is None or col_end is None:\n",
    "    raise ValueError(\n",
    "        f\"Couldn't find start/end-like columns in {BHLH_COORDS}. \"\n",
    "        f\"Looked for one of env_from/ali_from/start and env_to/ali_to/end. \"\n",
    "        f\"Have: {list(coords.columns)}\"\n",
    "    )\n",
    "\n",
    "coords = coords[[col_id, col_start, col_end]].rename(\n",
    "    columns={col_id: \"id\", col_start: \"start\", col_end: \"end\"}\n",
    ")\n",
    "coords[\"id\"] = coords[\"id\"].astype(str)\n",
    "coords[\"start\"] = coords[\"start\"].astype(int)\n",
    "coords[\"end\"]   = coords[\"end\"].astype(int)\n",
    "\n",
    "# Keep only proteins that appear in ALL.fimo_hits.filtered_perseq.tsv\n",
    "coords = coords[coords[\"id\"].isin(ids_from_fimo)].drop_duplicates(\"id\")\n",
    "print(\"bHLH coord rows kept:\", len(coords))\n",
    "coords.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e269e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bHLH subsequences: 89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 3) Load sequences and slice bHLH subsequences\n",
    "\n",
    "# FASTA IDs must match the 'id' values above (after whatever normalization you already use).\n",
    "seq_index = {}\n",
    "for rec in SeqIO.parse(str(TARGET_FASTA), \"fasta\"):\n",
    "    seq_index[rec.id] = rec.seq\n",
    "\n",
    "# sanity & slicing\n",
    "def safe_slice(seq, start1, end1):\n",
    "    # coords are 1-based inclusive; convert to 0-based slice\n",
    "    s = max(1, int(start1))\n",
    "    e = int(end1)\n",
    "    if s > e: s, e = e, s\n",
    "    s0 = s-1\n",
    "    # clamp\n",
    "    s0 = max(0, min(s0, len(seq)))\n",
    "    e0 = max(0, min(e, len(seq)))\n",
    "    return seq[s0:e0]\n",
    "\n",
    "missing = [pid for pid in coords[\"id\"] if pid not in seq_index]\n",
    "if missing:\n",
    "    print(f\"WARNING: {len(missing)} IDs have coords but not found in FASTA. (Showing up to 10): {missing[:10]}\")\n",
    "\n",
    "records = []\n",
    "for row in coords.itertuples(index=False):\n",
    "    pid, s, e = row.id, row.start, row.end\n",
    "    if pid not in seq_index: \n",
    "        continue\n",
    "    frag = safe_slice(seq_index[pid], s, e)\n",
    "    if len(frag) < 20:\n",
    "        # too short to be a meaningful bHLH; skip\n",
    "        continue\n",
    "    records.append(SeqRecord(Seq(str(frag)), id=pid, description=f\"bHLH:{s}-{e}\"))\n",
    "\n",
    "print(\"bHLH subsequences:\", len(records))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffa4b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insects: 15  |  Spiders: 74  |  Unknown: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4) Assign clades (spider vs insect) for each protein\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Determined from ASC_targets.fasta\n",
    "PREFIX_TO_CLADE = {\n",
    "    # spiders / chelicerates\n",
    "    \"Ptep\": \"spider\",   # Parasteatoda tepidariorum\n",
    "    \"Isca\": \"spider\",   # Ixodes scapularis (tick; chelicerate)\n",
    "    \"Abru\": \"spider\",   # Argiope bruennichi\n",
    "    \"Afer\": \"spider\",   # (assumed) Alopecosa ferox / spider lineage\n",
    "    \"Lpol\": \"spider\",   # (assumed) Latrodectus/Loxosceles lineage\n",
    "    \"Ppha\": \"spider\",   # Pholcus phalangioides\n",
    "    \"Dsil\": \"spider\",   # (assumed) Dysdera/Dolomedes silvestris\n",
    "    \"Hgra\": \"spider\",   # (assumed) Habronattus/Hasarius gramineus\n",
    "    \"Ssce\": \"spider\",   # (assumed) Stegodyphus lineage\n",
    "\n",
    "    # insects\n",
    "    \"Dmel\": \"insect\",   # Drosophila melanogaster\n",
    "    \"Amel\": \"insect\",   # Apis mellifera\n",
    "    \"Tcas\": \"insect\",   # Tribolium castaneum\n",
    "    \"Gmar\": \"insect\",   # (assumed) Gryllus/Gerris marginatus\n",
    "    \"Cdip\": \"insect\",   # (assumed) insect lineage\n",
    "}\n",
    "\n",
    "def id_prefix(pid: str) -> str:\n",
    "    # take token before first underscore, e.g. \"Abru\" from \"Abru_g14616.t1\"\n",
    "    return pid.split(\"_\", 1)[0]\n",
    "\n",
    "def guess_clade_from_prefix(pid: str) -> str:\n",
    "    pref = id_prefix(pid)\n",
    "    return PREFIX_TO_CLADE.get(pref, \"unknown\")\n",
    "\n",
    "id2clade = {r.id: guess_clade_from_prefix(r.id) for r in records}\n",
    "\n",
    "# partition\n",
    "spider_recs = [r for r in records if id2clade.get(r.id) == \"spider\"]\n",
    "insect_recs = [r for r in records if id2clade.get(r.id) == \"insect\"]\n",
    "unknown_recs= [r for r in records if id2clade.get(r.id) == \"unknown\"]\n",
    "print(f\"Insects: {len(insect_recs)}  |  Spiders: {len(spider_recs)}  |  Unknown: {len(unknown_recs)}\")\n",
    "\n",
    "# optional: write unknowns to a file for manual fix (should be empty with current FASTA)\n",
    "if unknown_recs:\n",
    "    with open(OUTDIR/\"unknown_prefix_ids.txt\",\"w\") as fh:\n",
    "        for r in unknown_recs:\n",
    "            fh.write(r.id + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da22ed6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insects: 15 | Spiders: 74 | Unknown: 0\n",
      "Running: mafft --auto results/weblogos_bHLH_by_lineage/bHLH_spiders.raw.faa\n",
      "Running: mafft --auto results/weblogos_bHLH_by_lineage/bHLH_insects.raw.faa\n",
      "Aligned: {'spider': True, 'insect': True}\n",
      "Saved: results/weblogos_bHLH_by_lineage/bHLH_spiders.logo.png | results/weblogos_bHLH_by_lineage/bHLH_spiders.logo.svg\n",
      "Saved: results/weblogos_bHLH_by_lineage/bHLH_insects.logo.png | results/weblogos_bHLH_by_lineage/bHLH_insects.logo.svg\n"
     ]
    }
   ],
   "source": [
    "#  RE-RUN SAFE BLOCK: split -> write FASTA -> MAFFT -> logos \n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "import subprocess, sys\n",
    "import pandas as pd\n",
    "\n",
    "# 0) Ensure OUTDIR exists\n",
    "OUTDIR = Path(\"results/weblogos_bHLH_by_lineage\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Prefix-based clade mapping for your IDs\n",
    "PREFIX_TO_CLADE = {\n",
    "    # spiders / chelicerates\n",
    "    \"Ptep\": \"spider\", \"Isca\": \"spider\", \"Abru\": \"spider\", \"Afer\": \"spider\",\n",
    "    \"Lpol\": \"spider\", \"Ppha\": \"spider\", \"Dsil\": \"spider\", \"Hgra\": \"spider\", \"Ssce\": \"spider\",\n",
    "    # insects\n",
    "    \"Dmel\": \"insect\", \"Amel\": \"insect\", \"Tcas\": \"insect\", \"Gmar\": \"insect\", \"Cdip\": \"insect\",\n",
    "}\n",
    "def _prefix(pid: str) -> str: return pid.split(\"_\", 1)[0]\n",
    "def _clade(pid: str) -> str: return PREFIX_TO_CLADE.get(_prefix(pid), \"unknown\")\n",
    "\n",
    "# 2) Expect 'records' already holds sliced bHLH SeqRecords (from the coords + FASTA step)\n",
    "assert 'records' in globals() and len(records) > 0, \"Missing 'records' (bHLH subsequences). Run the slicing cell first.\"\n",
    "\n",
    "spider_recs = [r for r in records if _clade(r.id) == \"spider\"]\n",
    "insect_recs = [r for r in records if _clade(r.id) == \"insect\"]\n",
    "unknown_recs= [r for r in records if _clade(r.id) == \"unknown\"]\n",
    "\n",
    "print(f\"Insects: {len(insect_recs)} | Spiders: {len(spider_recs)} | Unknown: {len(unknown_recs)}\")\n",
    "if unknown_recs:\n",
    "    with open(OUTDIR/\"unknown_prefix_ids.txt\",\"w\") as fh:\n",
    "        for r in unknown_recs: fh.write(r.id + \"\\n\")\n",
    "    print(\"Wrote unknown prefixes to\", OUTDIR/\"unknown_prefix_ids.txt\")\n",
    "\n",
    "# 3) Define and write raw FASTAs (this is where fa_spiders/fa_insects are created)\n",
    "fa_spiders = OUTDIR / \"bHLH_spiders.raw.faa\"\n",
    "fa_insects = OUTDIR / \"bHLH_insects.raw.faa\"\n",
    "if len(spider_recs) >= 1: SeqIO.write(spider_recs, str(fa_spiders), \"fasta\")\n",
    "if len(insect_recs) >= 1: SeqIO.write(insect_recs, str(fa_insects), \"fasta\")\n",
    "\n",
    "# 4) MAFFT wrapper (define if not already)\n",
    "try:\n",
    "    run_mafft\n",
    "except NameError:\n",
    "    MAFFT = \"mafft\"\n",
    "    def run_mafft(inp: Path, outp: Path, add_args=(\"--auto\",)):\n",
    "        if not inp.exists() or sum(1 for _ in SeqIO.parse(str(inp), \"fasta\")) < 2:\n",
    "            print(f\"Skip MAFFT: not enough sequences in {inp}\")\n",
    "            return False\n",
    "        cmd = [MAFFT, *add_args, str(inp)]\n",
    "        print(\"Running:\", \" \".join(cmd))\n",
    "        res = subprocess.run(cmd, capture_output=True, text=True)\n",
    "        if res.returncode != 0:\n",
    "            print(\"MAFFT error:\\n\", res.stderr[:2000])\n",
    "            return False\n",
    "        outp.write_text(res.stdout)\n",
    "        return True\n",
    "\n",
    "# 5) Align\n",
    "aln_spiders = OUTDIR / \"bHLH_spiders.aln.faa\"\n",
    "aln_insects = OUTDIR / \"bHLH_insects.aln.faa\"\n",
    "ok_sp = run_mafft(fa_spiders, aln_spiders) if len(spider_recs) >= 2 else False\n",
    "ok_in = run_mafft(fa_insects, aln_insects) if len(insect_recs) >= 2 else False\n",
    "print(\"Aligned:\", {\"spider\": ok_sp, \"insect\": ok_in})\n",
    "\n",
    "# 6) Logos (define helper if missing)\n",
    "try:\n",
    "    alignment_to_logo\n",
    "except NameError:\n",
    "    def _pip(pkg):\n",
    "        try: __import__(pkg)\n",
    "        except ImportError: subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "    _pip(\"logomaker\"); _pip(\"matplotlib\")\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import logomaker as lm\n",
    "\n",
    "    def alignment_to_logo(aln_faa: Path, out_png: Path, out_svg: Path):\n",
    "        seqs = [str(rec.seq) for rec in SeqIO.parse(str(aln_faa), \"fasta\")]\n",
    "        if len(seqs) < 2:\n",
    "            print(f\"Not enough seqs to make a logo: {aln_faa}\")\n",
    "            return\n",
    "        L = len(seqs[0])\n",
    "        if not all(len(s)==L for s in seqs):\n",
    "            raise ValueError(f\"Alignment {aln_faa} has variable lengths; check MAFFT.\")\n",
    "        alphabet = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "        cols = []\n",
    "        for i in range(L):\n",
    "            d = {aa:0 for aa in alphabet}\n",
    "            for s in seqs:\n",
    "                if s[i] in d: d[s[i]] += 1\n",
    "            cols.append(d)\n",
    "        df = pd.DataFrame(cols)\n",
    "        fig = plt.figure(figsize=(14, 3.2))\n",
    "        ax = fig.add_subplot(111)\n",
    "        lm.Logo(df, ax=ax, shade_below=.5, fade_below=.5, vpad=0.05, width=.98)\n",
    "        ax.set_xlabel(\"Alignment position\"); ax.set_ylabel(\"Information\")\n",
    "        ax.set_title(aln_faa.name.replace(\".aln.faa\",\"\").replace(\"_\",\" \").upper())\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(out_png, dpi=300); fig.savefig(out_svg); plt.close(fig)\n",
    "        print(\"Saved:\", out_png, \"|\", out_svg)\n",
    "\n",
    "# 7) Build logos if alignments exist\n",
    "if ok_sp:\n",
    "    alignment_to_logo(aln_spiders, OUTDIR/\"bHLH_spiders.logo.png\", OUTDIR/\"bHLH_spiders.logo.svg\")\n",
    "if ok_in:\n",
    "    alignment_to_logo(aln_insects, OUTDIR/\"bHLH_insects.logo.png\", OUTDIR/\"bHLH_insects.logo.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6c6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total (spiders+insects): 89\n",
      "Running: mafft --auto results/weblogos_bHLH_by_lineage/bHLH_all.raw.faa\n",
      "Saved: results/weblogos_bHLH_by_lineage/bHLH_all.logo.png | results/weblogos_bHLH_by_lineage/bHLH_all.logo.svg\n"
     ]
    }
   ],
   "source": [
    "#  COMBINED LOGO: spiders + insects together \n",
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "assert 'spider_recs' in globals() and 'insect_recs' in globals(), \"Run the clade-split cell first.\"\n",
    "\n",
    "OUTDIR = Path(\"results/weblogos_bHLH_by_lineage\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Combine and write raw FASTA\n",
    "all_recs = spider_recs + insect_recs\n",
    "print(f\"Total (spiders+insects): {len(all_recs)}\")\n",
    "fa_all = OUTDIR / \"bHLH_all.raw.faa\"\n",
    "SeqIO.write(all_recs, str(fa_all), \"fasta\")\n",
    "\n",
    "# 2) Align (needs >=2 sequences)\n",
    "aln_all = OUTDIR / \"bHLH_all.aln.faa\"\n",
    "ok_all = False\n",
    "if len(all_recs) >= 2:\n",
    "    ok_all = run_mafft(fa_all, aln_all)\n",
    "else:\n",
    "    print(\"Skip MAFFT: need at least 2 sequences for a combined logo.\")\n",
    "\n",
    "# 3) Build logo\n",
    "if ok_all:\n",
    "    alignment_to_logo(aln_all, OUTDIR/\"bHLH_all.logo.png\", OUTDIR/\"bHLH_all.logo.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) Provenance snapshot\n",
    "\n",
    "with open(OUTDIR/\"README.txt\",\"w\") as fh:\n",
    "    fh.write(textwrap.dedent(f\"\"\"\n",
    "    WebLogo of bHLH regions by lineage\n",
    "    ----------------------------------\n",
    "    Inputs:\n",
    "      FIMO per-seq: {FIMO_PERSEQ}\n",
    "      Targets FASTA: {TARGET_FASTA}\n",
    "      bHLH coords:  {BHLH_COORDS}\n",
    "      Taxon map:    {TAXON_MAP if TAXON_MAP else \"regex-based fallback\"}\n",
    "\n",
    "    Outputs:\n",
    "      Raw FASTA:    {fa_spiders.name}, {fa_insects.name}\n",
    "      Alignments:   {aln_spiders.name if ok_sp else \"NA\"}, {aln_insects.name if ok_in else \"NA\"}\n",
    "      Logos:        bHLH_spiders.logo.(png|svg), bHLH_insects.logo.(png|svg)\n",
    "\n",
    "    Notes:\n",
    "      - Proteins considered were those present in ALL.fimo_hits.filtered_perseq.tsv.\n",
    "      - Only the bHLH domain (start..end from coords table) was extracted.\n",
    "      - Logos are built from MAFFT alignments.\n",
    "    \"\"\").strip()+\"\\n\")\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d4dce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loaded 2123 FIMO hits\n",
      "\n",
      "Sequence counts by family:\n",
      "  ASCa: 37 sequences\n",
      "  ASCb: 14 sequences\n",
      "  ASCc: 15 sequences\n",
      "\n",
      "Loaded 89 bHLH domain coordinates\n",
      "\n",
      "After merging: 89 sequences with family and species info\n",
      "\n",
      "Loading target FASTA...\n",
      "Loaded 91 target sequences\n",
      "\n",
      "Extracting bHLH subsequences...\n",
      "Extracted 89 bHLH subsequences\n",
      "\n",
      "Organizing sequences by family and species...\n",
      "\n",
      "Sequence counts by group:\n",
      "  ASCa_combined: 36 sequences\n",
      "  ASCa_insects: 8 sequences\n",
      "  ASCa_spiders: 28 sequences\n",
      "  ASCb_combined: 14 sequences\n",
      "  ASCb_insects: 1 sequences\n",
      "  ASCb_spiders: 13 sequences\n",
      "  ASCc_combined: 15 sequences\n",
      "  ASCc_insects: 2 sequences\n",
      "  ASCc_spiders: 13 sequences\n",
      "\n",
      "======================================================================\n",
      "GENERATING WEBLOGOS\n",
      "======================================================================\n",
      "\n",
      "ASCa_combined: 36 sequences\n",
      "  Wrote raw FASTA: ASCa_combined_raw.faa\n",
      "  Running MAFFT on ASCa_combined_raw.faa (36 sequences)...\n",
      "  ✓ Saved: ASCa_combined_logo.png and ASCa_combined_logo.svg\n",
      "\n",
      "ASCa_insects: 8 sequences\n",
      "  Wrote raw FASTA: ASCa_insects_raw.faa\n",
      "  Running MAFFT on ASCa_insects_raw.faa (8 sequences)...\n",
      "  ✓ Saved: ASCa_insects_logo.png and ASCa_insects_logo.svg\n",
      "\n",
      "ASCa_spiders: 28 sequences\n",
      "  Wrote raw FASTA: ASCa_spiders_raw.faa\n",
      "  Running MAFFT on ASCa_spiders_raw.faa (28 sequences)...\n",
      "  ✓ Saved: ASCa_spiders_logo.png and ASCa_spiders_logo.svg\n",
      "\n",
      "ASCb_combined: 14 sequences\n",
      "  Wrote raw FASTA: ASCb_combined_raw.faa\n",
      "  Running MAFFT on ASCb_combined_raw.faa (14 sequences)...\n",
      "  ✓ Saved: ASCb_combined_logo.png and ASCb_combined_logo.svg\n",
      "\n",
      "ASCb_insects: Skipping (only 1 sequence(s))\n",
      "\n",
      "ASCb_spiders: 13 sequences\n",
      "  Wrote raw FASTA: ASCb_spiders_raw.faa\n",
      "  Running MAFFT on ASCb_spiders_raw.faa (13 sequences)...\n",
      "  ✓ Saved: ASCb_spiders_logo.png and ASCb_spiders_logo.svg\n",
      "\n",
      "ASCc_combined: 15 sequences\n",
      "  Wrote raw FASTA: ASCc_combined_raw.faa\n",
      "  Running MAFFT on ASCc_combined_raw.faa (15 sequences)...\n",
      "  ✓ Saved: ASCc_combined_logo.png and ASCc_combined_logo.svg\n",
      "\n",
      "ASCc_insects: 2 sequences\n",
      "  Wrote raw FASTA: ASCc_insects_raw.faa\n",
      "  Running MAFFT on ASCc_insects_raw.faa (2 sequences)...\n",
      "  ✓ Saved: ASCc_insects_logo.png and ASCc_insects_logo.svg\n",
      "\n",
      "ASCc_spiders: 13 sequences\n",
      "  Wrote raw FASTA: ASCc_spiders_raw.faa\n",
      "  Running MAFFT on ASCc_spiders_raw.faa (13 sequences)...\n",
      "  ✓ Saved: ASCc_spiders_logo.png and ASCc_spiders_logo.svg\n",
      "\n",
      "======================================================================\n",
      "COMPLETED!\n",
      "======================================================================\n",
      "\n",
      "All outputs saved to: /Users/gorkemdurmaz/Desktop/asc_project_10/weblogos_by_family_and_species\n",
      "\n",
      "Generated logos:\n",
      "  ✓ ASCa_combined: 36 sequences\n",
      "  ✓ ASCa_insects: 8 sequences\n",
      "  ✓ ASCa_spiders: 28 sequences\n",
      "  ✓ ASCb_combined: 14 sequences\n",
      "  ✗ ASCb_insects: Only 1 sequence(s) - skipped\n",
      "  ✓ ASCb_spiders: 13 sequences\n",
      "  ✓ ASCc_combined: 15 sequences\n",
      "  ✓ ASCc_insects: 2 sequences\n",
      "  ✓ ASCc_spiders: 13 sequences\n",
      "\n",
      "Files generated:\n",
      "  - *_raw.faa: Raw extracted bHLH sequences\n",
      "  - *_aligned.faa: MAFFT-aligned sequences\n",
      "  - *_logo.png: WebLogo in PNG format (300 dpi)\n",
      "  - *_logo.svg: WebLogo in SVG format (vector)\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "# Generate WebLogos for bHLH domains by Gene Family (ASCa, ASCb, ASCc) and Species\n",
    "\n",
    "# This code creates 9 logos:\n",
    "# - ASCa: combined, insects-only, spiders-only\n",
    "# - ASCb: combined, insects-only, spiders-only  \n",
    "# - ASCc: combined, insects-only, spiders-only\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "import sys\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "\n",
    "\n",
    "# Output directory\n",
    "OUTDIR = Path(\"weblogos_by_family_and_species\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# MAFFT for alignment\n",
    "MAFFT = \"mafft\"\n",
    "\n",
    "# Species classification based on prefix\n",
    "\n",
    "PREFIX_TO_SPECIES = {\n",
    "    # Spiders/Chelicerates\n",
    "    \"Ptep\": \"spider\", \"Isca\": \"spider\", \"Abru\": \"spider\", \"Afer\": \"spider\",\n",
    "    \"Lpol\": \"spider\", \"Ppha\": \"spider\", \"Dsil\": \"spider\", \"Hgra\": \"spider\", \"Ssce\": \"spider\", \"Gmar\": \"spider\", \"Ppse\": \"spider\", \"Cdip\": \"spider\",\n",
    "    # Insects\n",
    "    \"Dmel\": \"insect\", \"Amel\": \"insect\", \"Tcas\": \"insect\", \"Cdip\": \"insect\", \"Dsuz\": \"insect\", \"Bmor\": \"insect\", \"Agla\": \"insect\", \"Afun\": \"insect\", \"Mpha\": \"insect\", \"Fcan\": \"insect\"\n",
    "}\n",
    "\n",
    "\n",
    "def get_prefix(seq_id: str) -> str:\n",
    "    \"\"\"Extract prefix from sequence ID (e.g., 'Abru_g13702.t1' -> 'Abru')\"\"\"\n",
    "    return seq_id.split(\"_\", 1)[0]\n",
    "\n",
    "def get_species_group(seq_id: str) -> str:\n",
    "    \"\"\"Classify sequence as 'insect', 'spider', or 'unknown' based on prefix\"\"\"\n",
    "    prefix = get_prefix(seq_id)\n",
    "    return PREFIX_TO_SPECIES.get(prefix, \"unknown\")\n",
    "\n",
    "def get_family(target_family: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify into ASCa, ASCb, or ASCc based on target_family column.\n",
    "    - Returns the target_family value directly if it's ASCa, ASCb, or ASCc\n",
    "    - Otherwise returns 'other'\n",
    "    \"\"\"\n",
    "    if pd.isna(target_family):\n",
    "        return \"other\"\n",
    "    target_family = str(target_family).strip()\n",
    "    if target_family in ['ASCa', 'ASCb', 'ASCc']:\n",
    "        return target_family\n",
    "    else:\n",
    "        return \"other\"\n",
    "\n",
    "# ===========================\n",
    "# 1) LOAD DATA\n",
    "# ===========================\n",
    "print(\"Loading data...\")\n",
    "\n",
    "# Load FIMO per-sequence results\n",
    "fimo = pd.read_csv(FIMO_PERSEQ, sep=\"\\t\")\n",
    "print(f\"Loaded {len(fimo)} FIMO hits\")\n",
    "\n",
    "# Find the sequence ID column\n",
    "cand_cols = [c for c in fimo.columns if c.lower() in {\"sequence_name\", \"seq_name\", \"target\", \"seq_id\", \"sequence\"}]\n",
    "if not cand_cols:\n",
    "    raise ValueError(f\"Couldn't find an ID column in {FIMO_PERSEQ}. Columns: {list(fimo.columns)}\")\n",
    "seq_id_col = cand_cols[0]\n",
    "\n",
    "# Add family and species classifications\n",
    "fimo['family'] = fimo['target_family'].apply(get_family)\n",
    "fimo['species_group'] = fimo[seq_id_col].apply(get_species_group)\n",
    "\n",
    "# Get unique sequences per family\n",
    "print(\"\\nSequence counts by family:\")\n",
    "for family in ['ASCa', 'ASCb', 'ASCc']:\n",
    "    count = fimo[fimo['family'] == family][seq_id_col].nunique()\n",
    "    print(f\"  {family}: {count} sequences\")\n",
    "\n",
    "# Load bHLH coordinates\n",
    "coords = pd.read_csv(BHLH_COORDS, sep=\"\\t\")\n",
    "\n",
    "# Standardize column names\n",
    "lower2orig = {c.lower(): c for c in coords.columns}\n",
    "def pick_col(df_cols_lower_to_orig, *candidates):\n",
    "    for c in candidates:\n",
    "        if c in df_cols_lower_to_orig:\n",
    "            return df_cols_lower_to_orig[c]\n",
    "    return None\n",
    "\n",
    "col_id = pick_col(lower2orig, \"id\", \"seq_id\", \"protein\", \"name\")\n",
    "col_start = pick_col(lower2orig, \"env_from\", \"ali_from\", \"start\", \"query_start\")\n",
    "col_end = pick_col(lower2orig, \"env_to\", \"ali_to\", \"end\", \"query_end\")\n",
    "\n",
    "if not all([col_id, col_start, col_end]):\n",
    "    raise ValueError(f\"Couldn't find required columns in {BHLH_COORDS}\")\n",
    "\n",
    "coords = coords[[col_id, col_start, col_end]].rename(\n",
    "    columns={col_id: \"seq_id\", col_start: \"start\", col_end: \"end\"}\n",
    ")\n",
    "coords[\"seq_id\"] = coords[\"seq_id\"].astype(str)\n",
    "coords[\"start\"] = coords[\"start\"].astype(int)\n",
    "coords[\"end\"] = coords[\"end\"].astype(int)\n",
    "\n",
    "print(f\"\\nLoaded {len(coords)} bHLH domain coordinates\")\n",
    "\n",
    "# Merge FIMO data with coordinates to get family info for each sequence\n",
    "# Keep only one row per sequence (in case there are duplicates)\n",
    "fimo_unique = fimo.groupby(seq_id_col).first().reset_index()\n",
    "coords_with_family = coords.merge(\n",
    "    fimo_unique[[seq_id_col, 'family', 'species_group']], \n",
    "    left_on='seq_id', \n",
    "    right_on=seq_id_col,\n",
    "    how='left'\n",
    ")\n",
    "coords_with_family = coords_with_family.dropna(subset=['family', 'species_group'])\n",
    "\n",
    "print(f\"\\nAfter merging: {len(coords_with_family)} sequences with family and species info\")\n",
    "\n",
    "# Load target sequences\n",
    "print(\"\\nLoading target FASTA...\")\n",
    "seq_dict = {rec.id: rec for rec in SeqIO.parse(str(TARGET_FASTA), \"fasta\")}\n",
    "print(f\"Loaded {len(seq_dict)} target sequences\")\n",
    "\n",
    "# ===========================\n",
    "# 2) EXTRACT bHLH SUBSEQUENCES\n",
    "# ===========================\n",
    "print(\"\\nExtracting bHLH subsequences...\")\n",
    "\n",
    "all_bhlh_records = []\n",
    "for _, row in coords_with_family.iterrows():\n",
    "    seq_id = row['seq_id']\n",
    "    if seq_id not in seq_dict:\n",
    "        continue\n",
    "    \n",
    "    full_seq = seq_dict[seq_id]\n",
    "    start = row['start'] - 1  # Convert to 0-based\n",
    "    end = row['end']  # End is inclusive in 1-based, exclusive in Python slicing\n",
    "    \n",
    "    bhlh_seq = str(full_seq.seq[start:end])\n",
    "    \n",
    "    # Create new record with family and species in description\n",
    "    new_rec = SeqRecord(\n",
    "        Seq(bhlh_seq),\n",
    "        id=seq_id,\n",
    "        description=f\"family={row['family']} species={row['species_group']}\"\n",
    "    )\n",
    "    all_bhlh_records.append((new_rec, row['family'], row['species_group']))\n",
    "\n",
    "print(f\"Extracted {len(all_bhlh_records)} bHLH subsequences\")\n",
    "\n",
    "# ===========================\n",
    "# 3) ORGANIZE BY FAMILY AND SPECIES\n",
    "# ===========================\n",
    "print(\"\\nOrganizing sequences by family and species...\")\n",
    "\n",
    "# Dictionary to hold sequences for each combination\n",
    "sequence_groups = {\n",
    "    'ASCa_combined': [],\n",
    "    'ASCa_insects': [],\n",
    "    'ASCa_spiders': [],\n",
    "    'ASCb_combined': [],\n",
    "    'ASCb_insects': [],\n",
    "    'ASCb_spiders': [],\n",
    "    'ASCc_combined': [],\n",
    "    'ASCc_insects': [],\n",
    "    'ASCc_spiders': [],\n",
    "}\n",
    "\n",
    "for rec, family, species_group in all_bhlh_records:\n",
    "    if family == 'ASCa':\n",
    "        sequence_groups['ASCa_combined'].append(rec)\n",
    "        if species_group == 'insect':\n",
    "            sequence_groups['ASCa_insects'].append(rec)\n",
    "        elif species_group == 'spider':\n",
    "            sequence_groups['ASCa_spiders'].append(rec)\n",
    "    elif family == 'ASCb':\n",
    "        sequence_groups['ASCb_combined'].append(rec)\n",
    "        if species_group == 'insect':\n",
    "            sequence_groups['ASCb_insects'].append(rec)\n",
    "        elif species_group == 'spider':\n",
    "            sequence_groups['ASCb_spiders'].append(rec)\n",
    "    elif family == 'ASCc':\n",
    "        sequence_groups['ASCc_combined'].append(rec)\n",
    "        if species_group == 'insect':\n",
    "            sequence_groups['ASCc_insects'].append(rec)\n",
    "        elif species_group == 'spider':\n",
    "            sequence_groups['ASCc_spiders'].append(rec)\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSequence counts by group:\")\n",
    "for group_name, seqs in sequence_groups.items():\n",
    "    print(f\"  {group_name}: {len(seqs)} sequences\")\n",
    "\n",
    "# ===========================\n",
    "# 4) ALIGNMENT FUNCTION\n",
    "# ===========================\n",
    "def run_mafft(input_fasta: Path, output_fasta: Path) -> bool:\n",
    "    \"\"\"Run MAFFT alignment on input FASTA, save to output FASTA\"\"\"\n",
    "    if not input_fasta.exists():\n",
    "        print(f\"  Input file not found: {input_fasta}\")\n",
    "        return False\n",
    "    \n",
    "    n_seqs = sum(1 for _ in SeqIO.parse(str(input_fasta), \"fasta\"))\n",
    "    if n_seqs < 2:\n",
    "        print(f\"  Skip MAFFT: only {n_seqs} sequence(s) in {input_fasta.name}\")\n",
    "        return False\n",
    "    \n",
    "    cmd = [MAFFT, \"--auto\", str(input_fasta)]\n",
    "    print(f\"  Running MAFFT on {input_fasta.name} ({n_seqs} sequences)...\")\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode != 0:\n",
    "        print(f\"  MAFFT error: {result.stderr[:500]}\")\n",
    "        return False\n",
    "    \n",
    "    output_fasta.write_text(result.stdout)\n",
    "    return True\n",
    "\n",
    "# ===========================\n",
    "# 5) LOGO GENERATION FUNCTION\n",
    "# ===========================\n",
    "def alignment_to_logo(aln_fasta: Path, out_png: Path, out_svg: Path, title: str):\n",
    "    \"\"\"Generate sequence logo from aligned FASTA\"\"\"\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        import logomaker as lm\n",
    "    except ImportError:\n",
    "        print(\"Installing logomaker and matplotlib...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"logomaker\", \"matplotlib\"])\n",
    "        import matplotlib.pyplot as plt\n",
    "        import logomaker as lm\n",
    "    \n",
    "    # Read sequences\n",
    "    seqs = [str(rec.seq) for rec in SeqIO.parse(str(aln_fasta), \"fasta\")]\n",
    "    if len(seqs) < 2:\n",
    "        print(f\"  Not enough sequences for logo: {aln_fasta.name}\")\n",
    "        return\n",
    "    \n",
    "    # Check alignment length consistency\n",
    "    L = len(seqs[0])\n",
    "    if not all(len(s) == L for s in seqs):\n",
    "        print(f\"  Warning: Variable length sequences in {aln_fasta.name}\")\n",
    "        return\n",
    "    \n",
    "    # Count amino acids at each position\n",
    "    alphabet = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "    position_counts = []\n",
    "    for i in range(L):\n",
    "        counts = {aa: 0 for aa in alphabet}\n",
    "        for seq in seqs:\n",
    "            if seq[i] in counts:\n",
    "                counts[seq[i]] += 1\n",
    "        position_counts.append(counts)\n",
    "    \n",
    "    # Create DataFrame for logomaker\n",
    "    df = pd.DataFrame(position_counts)\n",
    "    \n",
    "    # Generate logo\n",
    "    fig = plt.figure(figsize=(16, 3.5))\n",
    "    ax = fig.add_subplot(111)\n",
    "    lm.Logo(df, ax=ax, shade_below=0.5, fade_below=0.5, vpad=0.05, width=0.98)\n",
    "    ax.set_xlabel(\"Alignment Position\", fontsize=12)\n",
    "    ax.set_ylabel(\"Information (bits)\", fontsize=12)\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save\n",
    "    fig.savefig(out_png, dpi=300, bbox_inches='tight')\n",
    "    fig.savefig(out_svg, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "    print(f\"  ✓ Saved: {out_png.name} and {out_svg.name}\")\n",
    "\n",
    "# ===========================\n",
    "# 6) GENERATE ALL LOGOS\n",
    "# ===========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING WEBLOGOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for group_name, records in sequence_groups.items():\n",
    "    if len(records) < 2:\n",
    "        print(f\"\\n{group_name}: Skipping (only {len(records)} sequence(s))\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{group_name}: {len(records)} sequences\")\n",
    "    \n",
    "    # Write raw FASTA\n",
    "    raw_fasta = OUTDIR / f\"{group_name}_raw.faa\"\n",
    "    SeqIO.write(records, str(raw_fasta), \"fasta\")\n",
    "    print(f\"  Wrote raw FASTA: {raw_fasta.name}\")\n",
    "    \n",
    "    # Align with MAFFT\n",
    "    aln_fasta = OUTDIR / f\"{group_name}_aligned.faa\"\n",
    "    success = run_mafft(raw_fasta, aln_fasta)\n",
    "    \n",
    "    if not success:\n",
    "        print(f\"  Skipping logo generation for {group_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Generate logo\n",
    "    out_png = OUTDIR / f\"{group_name}_logo.png\"\n",
    "    out_svg = OUTDIR / f\"{group_name}_logo.svg\"\n",
    "    \n",
    "    # Create nice title\n",
    "    family = group_name.split('_')[0]\n",
    "    species = group_name.split('_')[1]\n",
    "    if species == 'combined':\n",
    "        title = f\"{family} bHLH Domain - All Species (n={len(records)})\"\n",
    "    elif species == 'insects':\n",
    "        title = f\"{family} bHLH Domain - Insects Only (n={len(records)})\"\n",
    "    elif species == 'spiders':\n",
    "        title = f\"{family} bHLH Domain - Spiders Only (n={len(records)})\"\n",
    "    else:\n",
    "        title = f\"{family} bHLH Domain - {species} (n={len(records)})\"\n",
    "    \n",
    "    alignment_to_logo(aln_fasta, out_png, out_svg, title)\n",
    "\n",
    "# ===========================\n",
    "# 7) SUMMARY\n",
    "# ===========================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAll outputs saved to: {OUTDIR.absolute()}\")\n",
    "print(\"\\nGenerated logos:\")\n",
    "for group_name, records in sequence_groups.items():\n",
    "    if len(records) >= 2:\n",
    "        print(f\"  ✓ {group_name}: {len(records)} sequences\")\n",
    "    else:\n",
    "        print(f\"  ✗ {group_name}: Only {len(records)} sequence(s) - skipped\")\n",
    "\n",
    "print(\"\\nFiles generated:\")\n",
    "print(\"  - *_raw.faa: Raw extracted bHLH sequences\")\n",
    "print(\"  - *_aligned.faa: MAFFT-aligned sequences\")\n",
    "print(\"  - *_logo.png: WebLogo in PNG format (300 dpi)\")\n",
    "print(\"  - *_logo.svg: WebLogo in SVG format (vector)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03787943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "bHLH DIAGNOSTIC ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "ASCa_combined:\n",
      "  Sequences: 36\n",
      "  Length range: 50-75 aa\n",
      "  Mean ± SD: 58.1 ± 7.6 aa\n",
      "  Alignment: 75 positions, 22.5% gaps\n",
      "  Mean entropy: 1.17 bits\n",
      "  Conserved positions (<0.5 bits): 25/75 (33.3%)\n",
      "  Sample alignment (first 3 seqs, 60 positions):\n",
      "    Abru_g14616.t1  : -VARRNERERKRVRLVNMGFAKLRQYIP---------------------TTGRPGKRLSK\n",
      "    Abru_g14798.t1  : SVARRNARERKRVCLVNMGFANLRDHIPPHLTVQAGPPSKSRSG----NNSAASNKKLSK\n",
      "    Abru_g14799.t1  : AVSRRNARERKRVRLVNLGFSTLRERVP----------------------PGAKNKKLSK\n",
      "\n",
      "ASCa_insects:\n",
      "  Sequences: 8\n",
      "  Length range: 59-69 aa\n",
      "  Mean ± SD: 64.1 ± 2.8 aa\n",
      "  Alignment: 70 positions, 8.4% gaps\n",
      "  Mean entropy: 0.62 bits\n",
      "  Conserved positions (<0.5 bits): 38/70 (54.3%)\n",
      "  Sample alignment (first 3 seqs, 60 positions):\n",
      "    Amel_g4745.t2   : -VARRNARERNRVKQVNNGFATLRQHIPQSVAQALGGSTAGTHGGSRAGSKKLSKVETLR\n",
      "    Amel_g4746.t1   : AVARRNARERNRVKQVNNGFATLRQHIPSHIAAGYGD---------RG--KKLSKVETLR\n",
      "    Dmel_achaete_NP_: -VIRRNARERNRVKQVNNGFSQLRQHIPAAVIADLSNGRR---GIGPGANKKLSKVSTLK\n",
      "\n",
      "ASCa_spiders:\n",
      "  Sequences: 28\n",
      "  Length range: 50-75 aa\n",
      "  Mean ± SD: 56.4 ± 7.6 aa\n",
      "  Alignment: 75 positions, 24.8% gaps\n",
      "  Mean entropy: 0.90 bits\n",
      "  Conserved positions (<0.5 bits): 29/75 (38.7%)\n",
      "  Sample alignment (first 3 seqs, 60 positions):\n",
      "    Abru_g14616.t1  : -VARRNERERKRVRLVNMGFAKLRQYIP---------------------TTGRPGKRLSK\n",
      "    Abru_g14798.t1  : SVARRNARERKRVCLVNMGFANLRDHIPPHLTVQAGPPSKSRSG----NNSAASNKKLSK\n",
      "    Abru_g14799.t1  : AVSRRNARERKRVRLVNLGFSTLRERVP----------------------PGAKNKKLSK\n",
      "\n",
      "ASCb_combined:\n",
      "  Sequences: 14\n",
      "  Length range: 50-57 aa\n",
      "  Mean ± SD: 52.9 ± 1.9 aa\n",
      "  Alignment: 57 positions, 7.1% gaps\n",
      "  Mean entropy: 0.59 bits\n",
      "  Conserved positions (<0.5 bits): 34/57 (59.6%)\n",
      "  Sample alignment (first 3 seqs, 60 positions):\n",
      "    Abru_g3556.t2   : --RRNERERQRVRSVNDGFSRLRNHLPRN----VQIKRRQSKVETLRHAINYIKQLQ\n",
      "    Abru_g3965.t1   : IRRRNERERQRVRNVNDGFERLKSHIPLN---AKDKDKRLSKVEILRMAIRYIRNLQ\n",
      "    Afer_g14943.t1  : IRRRNERERQRVRNVNDGFERLKNHLPIN---GKDKDKRLSKVEILRMAIRYIRNLQ\n",
      "\n",
      "ASCb_spiders:\n",
      "  Sequences: 13\n",
      "  Length range: 50-54 aa\n",
      "  Mean ± SD: 52.6 ± 1.5 aa\n",
      "  Alignment: 54 positions, 2.6% gaps\n",
      "  Mean entropy: 0.51 bits\n",
      "  Conserved positions (<0.5 bits): 35/54 (64.8%)\n",
      "  Sample alignment (first 3 seqs, 60 positions):\n",
      "    Abru_g3556.t2   : --RRNERERQRVRSVNDGFSRLRNHLPRNVQIK-RRQSKVETLRHAINYIKQLQ\n",
      "    Abru_g3965.t1   : IRRRNERERQRVRNVNDGFERLKSHIPLNAKDKDKRLSKVEILRMAIRYIRNLQ\n",
      "    Afer_g14943.t1  : IRRRNERERQRVRNVNDGFERLKNHLPINGKDKDKRLSKVEILRMAIRYIRNLQ\n",
      "\n",
      "ASCc_combined:\n",
      "  Sequences: 15\n",
      "  Length range: 52-55 aa\n",
      "  Mean ± SD: 52.3 ± 0.8 aa\n",
      "  Alignment: 56 positions, 6.7% gaps\n",
      "  Mean entropy: 0.43 bits\n",
      "  Conserved positions (<0.5 bits): 38/56 (67.9%)\n",
      "  Sample alignment (first 3 seqs, 60 positions):\n",
      "    Abru_g13702.t1  : VARRNARERRRVQAVNTAFSRLRRSVPAE---N-KNKRLSKVKTLHRAIEYIQMLQ\n",
      "    Abru_g18241.t1  : VARRNARERRRVEAVNSAFAKLRKCVPIE---N-RNKRLSKVKTLHRAIEYINGLQ\n",
      "    Afer_g7508.t1   : VARRNARERKRVQAVNSAFAKLRKSVPME---N-RNKRLSKVKTLHRAIEYINGLQ\n",
      "\n",
      "ASCc_insects:\n",
      "  Sequences: 2\n",
      "  Length range: 53-55 aa\n",
      "  Mean ± SD: 54.0 ± 1.0 aa\n",
      "  Alignment: 55 positions, 1.8% gaps\n",
      "  Mean entropy: 0.24 bits\n",
      "  Conserved positions (<0.5 bits): 42/55 (76.4%)\n",
      "  Sample alignment (first 3 seqs, 60 positions):\n",
      "    Cdip_g8855.t2   : VARRNARERRRVQAVNSAFYNLRMAVPGDSNASRGKRVSKVKTLQRAIDYIYVLQ\n",
      "    Tcas_XP_00819171: VARRNARERRRVQAVNSAFARLRKVVPLEN--TRGKRVSKVKTLQQAIEYIQALV\n",
      "\n",
      "ASCc_spiders:\n",
      "  Sequences: 13\n",
      "  Length range: 52-52 aa\n",
      "  Mean ± SD: 52.0 ± 0.0 aa\n",
      "  Alignment: 52 positions, 0.0% gaps\n",
      "  Mean entropy: 0.38 bits\n",
      "  Conserved positions (<0.5 bits): 39/52 (75.0%)\n",
      "  Sample alignment (first 3 seqs, 60 positions):\n",
      "    Abru_g13702.t1  : VARRNARERRRVQAVNTAFSRLRRSVPAENKNKRLSKVKTLHRAIEYIQMLQ\n",
      "    Abru_g18241.t1  : VARRNARERRRVEAVNSAFAKLRKCVPIENRNKRLSKVKTLHRAIEYINGLQ\n",
      "    Afer_g7508.t1   : VARRNARERKRVQAVNSAFAKLRKSVPMENRNKRLSKVKTLHRAIEYINGLQ\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "WD = Path(\"weblogos_by_family_and_species\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"bHLH DIAGNOSTIC ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for fam in [\"ASCa\", \"ASCb\", \"ASCc\"]:\n",
    "    for sp in [\"combined\", \"insects\", \"spiders\"]:\n",
    "        g = f\"{fam}_{sp}\"\n",
    "        raw = WD / f\"{g}_raw.faa\"\n",
    "        aln = WD / f\"{g}_aligned.faa\"\n",
    "        \n",
    "        if not raw.exists():\n",
    "            continue\n",
    "            \n",
    "        seqs = list(SeqIO.parse(str(raw), \"fasta\"))\n",
    "        lens = [len(s.seq) for s in seqs]\n",
    "        \n",
    "        print(f\"\\n{g}:\")\n",
    "        print(f\"  Sequences: {len(seqs)}\")\n",
    "        print(f\"  Length range: {min(lens)}-{max(lens)} aa\")\n",
    "        print(f\"  Mean ± SD: {np.mean(lens):.1f} ± {np.std(lens):.1f} aa\")\n",
    "        \n",
    "        if aln.exists():\n",
    "            aseqs = [str(r.seq) for r in SeqIO.parse(str(aln), \"fasta\")]\n",
    "            L = len(aseqs[0])\n",
    "            gaps = sum(s.count('-') for s in aseqs)\n",
    "            gap_pct = 100 * gaps / (len(aseqs) * L)\n",
    "            print(f\"  Alignment: {L} positions, {gap_pct:.1f}% gaps\")\n",
    "            \n",
    "            # Calculate entropy\n",
    "            entropies = []\n",
    "            for i in range(L):\n",
    "                col = [s[i] for s in aseqs if s[i] != '-']\n",
    "                if col:\n",
    "                    counts = Counter(col)\n",
    "                    total = sum(counts.values())\n",
    "                    ent = -sum((c/total) * np.log2(c/total) for c in counts.values())\n",
    "                    entropies.append(ent)\n",
    "            \n",
    "            print(f\"  Mean entropy: {np.mean(entropies):.2f} bits\")\n",
    "            conserved = sum(1 for e in entropies if e < 0.5)\n",
    "            print(f\"  Conserved positions (<0.5 bits): {conserved}/{L} ({100*conserved/L:.1f}%)\")\n",
    "            \n",
    "            print(f\"  Sample alignment (first 3 seqs, 60 positions):\")\n",
    "            for r in list(SeqIO.parse(str(aln), \"fasta\"))[:3]:\n",
    "                print(f\"    {r.id[:16]:16s}: {str(r.seq)[:60]}\")\n",
    "        \n",
    "        # Flag problems\n",
    "        if max(lens) - min(lens) > 30:\n",
    "            print(f\"  ⚠️  High length variation ({max(lens)-min(lens)} aa)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63881d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Figure 1: ASCa...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/mg_w6dbd39q6th2fvghj7bt00000gn/T/ipykernel_28622/3837532629.py:76: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved: Figure1_ASCa_bHLH.png/.svg\n",
      "Generating Figure 2: ASCb...\n",
      "  ✓ Saved: Figure2_ASCb_bHLH.png/.svg\n",
      "Generating Figure 3: ASCc...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/mg_w6dbd39q6th2fvghj7bt00000gn/T/ipykernel_28622/3837532629.py:144: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ Saved: Figure3_ASCc_bHLH.png/.svg\n",
      "\n",
      "======================================================================\n",
      "PUBLICATION FIGURES COMPLETE\n",
      "======================================================================\n",
      "\n",
      "All figures saved to: /Users/gorkemdurmaz/Desktop/asc_project_10/publication_figures\n",
      "\n",
      "Generated files:\n",
      "  - Figure1_ASCa_bHLH.png/.svg (Spiders + Insects)\n",
      "  - Figure2_ASCb_bHLH.png/.svg (Spiders only)\n",
      "  - Figure3_ASCc_bHLH.png/.svg (Spiders + Insects)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ================================================================================\n",
    "# Generate publication-ready multi-panel figures for ASC family bHLH domains\n",
    "# ================================================================================\n",
    "# Creates 3 figures:\n",
    "#   Figure 1: ASCa (spiders top, insects bottom)\n",
    "#   Figure 2: ASCb (spiders only)\n",
    "#   Figure 3: ASCc (spiders top, insects bottom)\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import logomaker as lm\n",
    "\n",
    "# Configuration\n",
    "WEBLOGOS_DIR = Path(\"weblogos_by_family_and_species\")\n",
    "OUTPUT_DIR = Path(\"publication_figures\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def alignment_to_counts_matrix(aln_fasta):\n",
    "    \"\"\"Convert aligned FASTA to counts matrix for logomaker\"\"\"\n",
    "    seqs = [str(rec.seq) for rec in SeqIO.parse(str(aln_fasta), \"fasta\")]\n",
    "    if len(seqs) < 1:\n",
    "        return None\n",
    "    \n",
    "    L = len(seqs[0])\n",
    "    alphabet = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
    "    \n",
    "    position_counts = []\n",
    "    for i in range(L):\n",
    "        counts = {aa: 0 for aa in alphabet}\n",
    "        for seq in seqs:\n",
    "            if seq[i] in counts:\n",
    "                counts[seq[i]] += 1\n",
    "        position_counts.append(counts)\n",
    "    \n",
    "    return pd.DataFrame(position_counts)\n",
    "\n",
    "# ================================================================================\n",
    "# FIGURE 1: ASCa (Spiders + Insects)\n",
    "# ================================================================================\n",
    "print(\"Generating Figure 1: ASCa...\")\n",
    "\n",
    "fig1 = plt.figure(figsize=(16, 6))\n",
    "gs1 = gridspec.GridSpec(2, 1, figure=fig1, height_ratios=[1, 1], hspace=0.7)\n",
    "\n",
    "# ASCa Spiders (top)\n",
    "ax1_top = fig1.add_subplot(gs1[0])\n",
    "aln_asca_spiders = WEBLOGOS_DIR / \"ASCa_spiders_aligned.faa\"\n",
    "df_asca_spiders = alignment_to_counts_matrix(aln_asca_spiders)\n",
    "n_asca_spiders = sum(1 for _ in SeqIO.parse(str(WEBLOGOS_DIR / \"ASCa_spiders_raw.faa\"), \"fasta\"))\n",
    "\n",
    "lm.Logo(df_asca_spiders, ax=ax1_top, shade_below=0.5, fade_below=0.5, \n",
    "        vpad=0.05, width=0.98, font_name='Arial')\n",
    "ax1_top.set_xlabel(\"Alignment Position\", fontsize=13, fontweight='bold')\n",
    "ax1_top.set_ylabel(\"Information (bits)\", fontsize=13, fontweight='bold')\n",
    "ax1_top.set_title(f\"ASCa - Spiders (n={n_asca_spiders})\", \n",
    "                  fontsize=15, fontweight='bold', pad=10)\n",
    "ax1_top.tick_params(labelsize=11)\n",
    "\n",
    "# ASCa Insects (bottom)\n",
    "ax1_bottom = fig1.add_subplot(gs1[1])\n",
    "aln_asca_insects = WEBLOGOS_DIR / \"ASCa_insects_aligned.faa\"\n",
    "df_asca_insects = alignment_to_counts_matrix(aln_asca_insects)\n",
    "n_asca_insects = sum(1 for _ in SeqIO.parse(str(WEBLOGOS_DIR / \"ASCa_insects_raw.faa\"), \"fasta\"))\n",
    "\n",
    "lm.Logo(df_asca_insects, ax=ax1_bottom, shade_below=0.5, fade_below=0.5, \n",
    "        vpad=0.05, width=0.98, font_name='Arial')\n",
    "ax1_bottom.set_xlabel(\"Alignment Position\", fontsize=13, fontweight='bold')\n",
    "ax1_bottom.set_ylabel(\"Information (bits)\", fontsize=13, fontweight='bold')\n",
    "ax1_bottom.set_title(f\"ASCa - Insects (n={n_asca_insects})\", \n",
    "                     fontsize=15, fontweight='bold', pad=10)\n",
    "ax1_bottom.tick_params(labelsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig1.savefig(OUTPUT_DIR / \"Figure1_ASCa_bHLH.png\", dpi=300, bbox_inches='tight')\n",
    "fig1.savefig(OUTPUT_DIR / \"Figure1_ASCa_bHLH.svg\", bbox_inches='tight')\n",
    "plt.close(fig1)\n",
    "print(f\"  ✓ Saved: Figure1_ASCa_bHLH.png/.svg\")\n",
    "\n",
    "# ================================================================================\n",
    "# FIGURE 2: ASCb (Spiders only)\n",
    "# ================================================================================\n",
    "print(\"Generating Figure 2: ASCb...\")\n",
    "\n",
    "fig2 = plt.figure(figsize=(16, 3.5))\n",
    "ax2 = fig2.add_subplot(111)\n",
    "\n",
    "aln_ascb_spiders = WEBLOGOS_DIR / \"ASCb_spiders_aligned.faa\"\n",
    "df_ascb_spiders = alignment_to_counts_matrix(aln_ascb_spiders)\n",
    "n_ascb_spiders = sum(1 for _ in SeqIO.parse(str(WEBLOGOS_DIR / \"ASCb_spiders_raw.faa\"), \"fasta\"))\n",
    "\n",
    "lm.Logo(df_ascb_spiders, ax=ax2, shade_below=0.5, fade_below=0.5, \n",
    "        vpad=0.05, width=0.98, font_name='Arial')\n",
    "ax2.set_xlabel(\"Alignment Position\", fontsize=13, fontweight='bold')\n",
    "ax2.set_ylabel(\"Information (bits)\", fontsize=13, fontweight='bold')\n",
    "ax2.set_title(f\"ASCb - Spiders (n={n_ascb_spiders})\", \n",
    "              fontsize=15, fontweight='bold', pad=10)\n",
    "ax2.tick_params(labelsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig2.savefig(OUTPUT_DIR / \"Figure2_ASCb_bHLH.png\", dpi=300, bbox_inches='tight')\n",
    "fig2.savefig(OUTPUT_DIR / \"Figure2_ASCb_bHLH.svg\", bbox_inches='tight')\n",
    "plt.close(fig2)\n",
    "print(f\"  ✓ Saved: Figure2_ASCb_bHLH.png/.svg\")\n",
    "\n",
    "# ================================================================================\n",
    "# FIGURE 3: ASCc (Spiders + Insects)\n",
    "# ================================================================================\n",
    "print(\"Generating Figure 3: ASCc...\")\n",
    "\n",
    "fig3 = plt.figure(figsize=(16, 6))\n",
    "gs3 = gridspec.GridSpec(2, 1, figure=fig3, height_ratios=[1, 1], hspace=0.7)\n",
    "\n",
    "# ASCc Spiders (top)\n",
    "ax3_top = fig3.add_subplot(gs3[0])\n",
    "aln_ascc_spiders = WEBLOGOS_DIR / \"ASCc_spiders_aligned.faa\"\n",
    "df_ascc_spiders = alignment_to_counts_matrix(aln_ascc_spiders)\n",
    "n_ascc_spiders = sum(1 for _ in SeqIO.parse(str(WEBLOGOS_DIR / \"ASCc_spiders_raw.faa\"), \"fasta\"))\n",
    "\n",
    "lm.Logo(df_ascc_spiders, ax=ax3_top, shade_below=0.5, fade_below=0.5, \n",
    "        vpad=0.05, width=0.98, font_name='Arial')\n",
    "ax3_top.set_xlabel(\"Alignment Position\", fontsize=13, fontweight='bold')\n",
    "ax3_top.set_ylabel(\"Information (bits)\", fontsize=13, fontweight='bold')\n",
    "ax3_top.set_title(f\"ASCc - Spiders (n={n_ascc_spiders})\", \n",
    "                  fontsize=15, fontweight='bold', pad=10)\n",
    "ax3_top.tick_params(labelsize=11)\n",
    "\n",
    "# ASCc Insects (bottom)\n",
    "ax3_bottom = fig3.add_subplot(gs3[1])\n",
    "aln_ascc_insects = WEBLOGOS_DIR / \"ASCc_insects_aligned.faa\"\n",
    "df_ascc_insects = alignment_to_counts_matrix(aln_ascc_insects)\n",
    "n_ascc_insects = sum(1 for _ in SeqIO.parse(str(WEBLOGOS_DIR / \"ASCc_insects_raw.faa\"), \"fasta\"))\n",
    "\n",
    "lm.Logo(df_ascc_insects, ax=ax3_bottom, shade_below=0.5, fade_below=0.5, \n",
    "        vpad=0.05, width=0.98, font_name='Arial')\n",
    "ax3_bottom.set_xlabel(\"Alignment Position\", fontsize=13, fontweight='bold')\n",
    "ax3_bottom.set_ylabel(\"Information (bits)\", fontsize=13, fontweight='bold')\n",
    "ax3_bottom.set_title(f\"ASCc - Insects (n={n_ascc_insects})\", \n",
    "                     fontsize=15, fontweight='bold', pad=10)\n",
    "ax3_bottom.tick_params(labelsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig3.savefig(OUTPUT_DIR / \"Figure3_ASCc_bHLH.png\", dpi=300, bbox_inches='tight')\n",
    "fig3.savefig(OUTPUT_DIR / \"Figure3_ASCc_bHLH.svg\", bbox_inches='tight')\n",
    "plt.close(fig3)\n",
    "print(f\"  ✓ Saved: Figure3_ASCc_bHLH.png/.svg\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PUBLICATION FIGURES COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nAll figures saved to: {OUTPUT_DIR.absolute()}\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - Figure1_ASCa_bHLH.png/.svg (Spiders + Insects)\")\n",
    "print(\"  - Figure2_ASCb_bHLH.png/.svg (Spiders only)\")\n",
    "print(\"  - Figure3_ASCc_bHLH.png/.svg (Spiders + Insects)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816001c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
